SALIDAS DEL NOTEBOOK: ejemplo01.ipynb
ExtraÃ­do el: 2025-06-11 14:26:49
============================================================

ğŸ”¹ CELDA 1:
CÃ³digo:
```python
# ============================================================================
# ENTREGABLE 3.1 - ANÃLISIS DE REDES NEURONALES RECURRENTES CON PYTORCH
# Adaptado para Jupyter Notebook
# ============================================================================

# CELDA 1: InstalaciÃ³n y configuraciÃ³n inicial
import sys
import subprocess

# Instalar dependencias si es necesario
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        print(f"Instalando {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# Lista de paquetes necesarios
packages = ['torch', 'torchvision', 'matplotlib', 'seaborn', 'pandas', 'scikit-learn', 'requests', 'numpy']

print("ğŸ”§ Verificando e instalando dependencias...")
for package in packages:
    install_package(package)
print("âœ… Todas las dependencias estÃ¡n instaladas")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ”§ Verificando e instalando dependencias...
   Instalando scikit-learn...
   âœ… Todas las dependencias estÃ¡n instaladas


--------------------------------------------------

ğŸ”¹ CELDA 2:
CÃ³digo:
```python
# CELDA 2: Importaciones y configuraciÃ³n
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import requests
import io
import time
import random
from collections import Counter
import pandas as pd
import warnings

# ConfiguraciÃ³n para Jupyter
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# ConfiguraciÃ³n inicial
print("=" * 60)
print("ENTREGABLE 3.1 - ANÃLISIS DE REDES NEURONALES RECURRENTES")
print("=" * 60)

# Verificar disponibilidad de CUDA
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Dispositivo seleccionado: {device}")
if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   Memoria GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"   Memoria GPU libre: {torch.cuda.memory_reserved(0) / 1e9:.1f} GB")
else:
    print("   âš ï¸  CUDA no disponible, usando CPU")
print()

# Configurar semilla para reproducibilidad
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)

print("âœ… ConfiguraciÃ³n inicial completada")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ============================================================
   ENTREGABLE 3.1 - ANÃLISIS DE REDES NEURONALES RECURRENTES
   ============================================================
   ğŸš€ Dispositivo seleccionado: cuda
      GPU: NVIDIA GeForce GTX 1660 Ti
      Memoria GPU disponible: 6.4 GB
      Memoria GPU libre: 0.5 GB
   
   âœ… ConfiguraciÃ³n inicial completada


--------------------------------------------------

ğŸ”¹ CELDA 3:
CÃ³digo:
```python
# CELDA 3: ConfiguraciÃ³n de hiperparÃ¡metros
print("ğŸ”§ ConfiguraciÃ³n de hiperparÃ¡metros:")

# HiperparÃ¡metros principales
SEQUENCE_LENGTH = 100
BATCH_SIZE = 64 if torch.cuda.is_available() else 32
EMBEDDING_DIM = 256
HIDDEN_SIZE = 512
NUM_LAYERS = 2
DROPOUT = 0.3

# Para anÃ¡lisis comparativo
LEARNING_RATES = [0.001, 0.0005, 0.0001]
EPOCHS_MAIN = 15  # Ã‰pocas para entrenamiento principal
EPOCHS_ANALYSIS = 5  # Ã‰pocas para anÃ¡lisis de hiperparÃ¡metros
BATCH_SIZES = [32, 64, 128]

print(f"   ğŸ“ Longitud de secuencia: {SEQUENCE_LENGTH}")
print(f"   ğŸ“¦ Batch size: {BATCH_SIZE}")
print(f"   ğŸ”¤ DimensiÃ³n de embedding: {EMBEDDING_DIM}")
print(f"   ğŸ§  TamaÃ±o oculto: {HIDDEN_SIZE}")
print(f"   ğŸ“š NÃºmero de capas: {NUM_LAYERS}")
print(f"   ğŸ¯ Dropout: {DROPOUT}")
print(f"   â±ï¸  Ã‰pocas principales: {EPOCHS_MAIN}")
print()

# Crear diccionario de configuraciÃ³n
config = {
    'sequence_length': SEQUENCE_LENGTH,
    'batch_size': BATCH_SIZE,
    'embedding_dim': EMBEDDING_DIM,
    'hidden_size': HIDDEN_SIZE,
    'num_layers': NUM_LAYERS,
    'dropout': DROPOUT,
    'epochs_main': EPOCHS_MAIN,
    'epochs_analysis': EPOCHS_ANALYSIS,
    'device': device
}

print("âœ… HiperparÃ¡metros configurados")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ”§ ConfiguraciÃ³n de hiperparÃ¡metros:
      ğŸ“ Longitud de secuencia: 100
      ğŸ“¦ Batch size: 64
      ğŸ”¤ DimensiÃ³n de embedding: 256
      ğŸ§  TamaÃ±o oculto: 512
      ğŸ“š NÃºmero de capas: 2
      ğŸ¯ Dropout: 0.3
      â±ï¸  Ã‰pocas principales: 15
   
   âœ… HiperparÃ¡metros configurados


--------------------------------------------------

ğŸ”¹ CELDA 4:
CÃ³digo:
```python
# CELDA 4: DefiniciÃ³n de clases y modelos
print("ğŸ—ï¸ Definiendo arquitecturas de modelos...")

# Dataset personalizado
class TextDataset(Dataset):
    def __init__(self, sequences, targets):
        self.sequences = torch.tensor(sequences, dtype=torch.long)
        self.targets = torch.tensor(targets, dtype=torch.long)
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        return self.sequences[idx], self.targets[idx]

# Modelo RNN Simple
class SimpleRNN(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout=0.3):
        super(SimpleRNN, self).__init__()
        self.name = "RNN Simple"
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, 
                         batch_first=True, dropout=dropout if num_layers > 1 else 0)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size, vocab_size)
        
    def forward(self, x):
        embedded = self.embedding(x)
        output, hidden = self.rnn(embedded)
        output = self.dropout(output[:, -1, :])
        output = self.fc(output)
        return output

# Modelo LSTM
class LSTMModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout=0.3):
        super(LSTMModel, self).__init__()
        self.name = "LSTM"
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, 
                           batch_first=True, dropout=dropout if num_layers > 1 else 0)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size, vocab_size)
        
    def forward(self, x):
        embedded = self.embedding(x)
        output, (hidden, cell) = self.lstm(embedded)
        output = self.dropout(output[:, -1, :])
        output = self.fc(output)
        return output

# Modelo GRU
class GRUModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout=0.3):
        super(GRUModel, self).__init__()
        self.name = "GRU"
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, 
                         batch_first=True, dropout=dropout if num_layers > 1 else 0)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size, vocab_size)
        
    def forward(self, x):
        embedded = self.embedding(x)
        output, hidden = self.gru(embedded)
        output = self.dropout(output[:, -1, :])
        output = self.fc(output)
        return output

print("âœ… Modelos definidos:")
print("   â€¢ RNN Simple: Arquitectura bÃ¡sica recurrente")
print("   â€¢ LSTM: Long Short-Term Memory")
print("   â€¢ GRU: Gated Recurrent Unit")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ—ï¸ Definiendo arquitecturas de modelos...
   âœ… Modelos definidos:
      â€¢ RNN Simple: Arquitectura bÃ¡sica recurrente
      â€¢ LSTM: Long Short-Term Memory
      â€¢ GRU: Gated Recurrent Unit


--------------------------------------------------

ğŸ”¹ CELDA 5:
CÃ³digo:
```python
# CELDA 5: Carga y procesamiento del texto desde archivo local
def download_and_process_text():
    print("ğŸ“¥ Cargando el texto del Quijote desde archivo local...")
    
    # Intentar cargar desde archivo local
    archivo_local = "donqui.txt"
    
    try:
        # Intentar diferentes encodings comunes
        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
        text = None
        
        for encoding in encodings:
            try:
                print(f"   ğŸ”„ Intentando con encoding: {encoding}")
                with open(archivo_local, 'r', encoding=encoding) as file:
                    text = file.read()
                print(f"   âœ… Archivo cargado exitosamente con encoding: {encoding}")
                break
            except UnicodeDecodeError:
                continue
            except FileNotFoundError:
                print(f"   âŒ Archivo '{archivo_local}' no encontrado")
                break
        
        if text is None:
            raise Exception("No se pudo leer el archivo con ningÃºn encoding")
        
        # Limpiar el texto
        text = text.strip()
        
        print(f"   ğŸ“Š Longitud: {len(text):,} caracteres")
        print(f"   ğŸ“„ LÃ­neas: {text.count(chr(10)):,}")
        print(f"   ğŸ“ Palabras aproximadas: {len(text.split()):,}")
        
        # Mostrar muestra del texto
        print(f"   ğŸ“– Muestra del texto:")
        muestra = text[:300].replace('\n', ' ').replace('\r', '')
        print(f"   '{muestra}...'")
        
        # Verificar que el texto tiene contenido suficiente
        if len(text) < 1000:
            print("   âš ï¸ Advertencia: El texto parece muy corto")
        
        return text
        
    except Exception as e:
        print(f"âŒ Error al cargar archivo local: {e}")
        print("ğŸ“ Usando texto de ejemplo extendido como respaldo...")
        
        # Texto de ejemplo mÃ¡s largo para entrenamiento
        base_text = """En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. Una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃºn palomino de aÃ±adidura los domingos, consumÃ­an las tres partes de su hacienda. El resto della concluÃ­an sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dÃ­as de entresemana se honraba con su vellorÃ­ de lo mÃ¡s fino.

Frisaba la edad de nuestro hidalgo con los cincuenta aÃ±os; era de complexiÃ³n recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. Quieren decir que tenÃ­a el sobrenombre de Quijada, o Quesada, que en esto hay alguna diferencia en los autores que deste caso escriben; aunque, por conjeturas verosÃ­miles, se deja entender que se llamaba Quejana. Pero esto importa poco a nuestro cuento; basta que en la narraciÃ³n dÃ©l no se salga un punto de la verdad.

Es, pues, de saber que este sobredicho hidalgo, los ratos que estaba ocioso, que eran los mÃ¡s del aÃ±o, se daba a leer libros de caballerÃ­as, con tanta aficiÃ³n y gusto, que olvidÃ³ casi de todo punto el ejercicio de la caza, y aun la administraciÃ³n de su hacienda; y llegÃ³ a tanto su curiosidad y desatino en esto, que vendiÃ³ muchas hanegas de tierra de sembradura para comprar libros de caballerÃ­as en que leer, y asÃ­, llevÃ³ a su casa todos cuantos pudo haber dellos.

De todos, ningunos le parecÃ­an tan bien como los que compuso el famoso Feliciano de Silva, porque la claridad de su prosa y aquellas entricadas razones suyas le parecÃ­an de perlas, y mÃ¡s cuando llegaba a leer aquellos requiebros y cartas de desafÃ­os, donde en muchas partes hallaba escrito: La razÃ³n de la sinrazÃ³n que a mi razÃ³n se hace, de tal manera mi razÃ³n enflaquece, que con razÃ³n me quejo de la vuestra fermosura. Y tambiÃ©n cuando leÃ­a: Los altos cielos que de vuestra divinidad divinamente con las estrellas os fortifican, y os hacen merecedora del merecimiento que merece la vuestra grandeza.

Con estas razones perdÃ­a el pobre caballero el juicio, y desvelÃ¡base por entenderlas y desentraÃ±arles el sentido, que no se lo sacara ni las entendiera el mesmo AristÃ³teles, si resucitara para sÃ³lo ello. No estaba muy bien con las heridas que don BelianÃ­s daba y recebÃ­a, porque se imaginaba que, por grandes maestros que le hubiesen curado, no dejarÃ­a de tener el rostro y todo el cuerpo lleno de cicatrices y seÃ±ales. Pero, con todo, alababa en su autor aquel acabar su libro con la promesa de aquella inacabable aventura, y muchas veces le vino deseo de tomar la pluma y dalle fin al pie de la letra, como allÃ­ se promete; y sin duda alguna lo hiciera, y aun saliera con ello, si otros mayores y continuos pensamientos no se lo estorbaran.

Tuvo muchas veces competencia con el cura de su lugar â€”que era hombre docto, graduado en SigÃ¼enzaâ€”,
y con otros eruditos de la ciudad, sobre el libro de caballerÃ­as, y con ellos discutÃ­a y discutÃ­a, y no se cansaba de ello, porque le encantaba el saber y el entender, y no le parecÃ­a cosa mala que le costase el alma."""

```

(Sin salidas)
--------------------------------------------------

ğŸ”¹ CELDA 6:
CÃ³digo:
```python
# CELDA 6: CreaciÃ³n de vocabulario y anÃ¡lisis estadÃ­stico
def create_vocabulary_and_analyze(text):
    print("ğŸ”¤ Creando vocabulario y analizando texto...")
    
    # Limpiar y procesar texto
    text_clean = text.lower()
    chars = sorted(list(set(text_clean)))
    
    # Crear mapeos
    char_to_idx = {char: idx for idx, char in enumerate(chars)}
    idx_to_char = {idx: char for idx, char in enumerate(chars)}
    vocab_size = len(chars)
    
    print(f"   ğŸ“š TamaÃ±o del vocabulario: {vocab_size}")
    print(f"   ğŸ”¤ Primeros 20 caracteres: {chars[:20]}")
    
    # AnÃ¡lisis estadÃ­stico
    char_freq = Counter(text_clean)
    total_chars = len(text_clean)
    space_count = text_clean.count(' ')
    newline_count = text_clean.count('\n')
    
    print(f"\nğŸ“Š EstadÃ­sticas del texto:")
    print(f"   ğŸ“ Caracteres totales: {total_chars:,}")
    print(f"   ğŸ”¤ Caracteres Ãºnicos: {vocab_size}")
    print(f"   ğŸ“ Palabras aproximadas: {space_count:,}")
    print(f"   ğŸ“„ LÃ­neas aproximadas: {newline_count:,}")
    
    # Top 10 caracteres mÃ¡s frecuentes
    print(f"\nğŸ† Top 10 caracteres mÃ¡s frecuentes:")
    special_chars = {' ': 'ESPACIO', '\n': 'NUEVA_LÃNEA', '\t': 'TAB'}
    
    for i, (char, freq) in enumerate(char_freq.most_common(10), 1):
        char_display = special_chars.get(char, char)
        percentage = (freq / total_chars) * 100
        print(f"   {i:2d}. {char_display:>10} - {freq:6,} ({percentage:5.2f}%)")
    
    return char_to_idx, idx_to_char, vocab_size, text_clean

# Ejecutar anÃ¡lisis
char_to_idx, idx_to_char, vocab_size, text_processed = create_vocabulary_and_analyze(text)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ”¤ Creando vocabulario y analizando texto...
      ğŸ“š TamaÃ±o del vocabulario: 31
      ğŸ”¤ Primeros 20 caracteres: [' ', ',', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r']
   
   ğŸ“Š EstadÃ­sticas del texto:
      ğŸ“ Caracteres totales: 111,400
      ğŸ”¤ Caracteres Ãºnicos: 31
      ğŸ“ Palabras aproximadas: 19,600
      ğŸ“„ LÃ­neas aproximadas: 0
   
   ğŸ† Top 10 caracteres mÃ¡s frecuentes:
       1.    ESPACIO - 19,600 (17.59%)
       2.          a - 11,200 (10.05%)
       3.          e -  9,200 ( 8.26%)
       4.          o -  9,000 ( 8.08%)
       5.          s -  7,600 ( 6.82%)
       6.          l -  7,400 ( 6.64%)
       7.          n -  6,600 ( 5.92%)
       8.          d -  5,000 ( 4.49%)
       9.          r -  4,800 ( 4.31%)
      10.          u -  4,000 ( 3.59%)


--------------------------------------------------

ğŸ”¹ CELDA 7:
CÃ³digo:
```python
# CELDA 8: CreaciÃ³n de secuencias de entrenamiento 
def create_sequences(text, char_to_idx, sequence_length):
    print("ğŸ”¢ Creando secuencias de entrenamiento...")
    
    # Convertir texto a Ã­ndices
    encoded_text = [char_to_idx[char] for char in text]
    
    sequences = []
    targets = []
    
    # Crear secuencias con ventana deslizante
    for i in range(len(encoded_text) - sequence_length):
        sequences.append(encoded_text[i:i + sequence_length])
        targets.append(encoded_text[i + sequence_length])
    
    sequences = np.array(sequences)
    targets = np.array(targets)
    
    print(f"   ğŸ“Š NÃºmero de secuencias creadas: {len(sequences):,}")
    print(f"   ğŸ“ Longitud de cada secuencia: {sequence_length}")
    print(f"   ğŸ¯ Ejemplo de secuencia: {sequences[0][:10]}...")
    print(f"   ğŸ¯ Ejemplo de target: {targets[0]}")
    
    # Mostrar ejemplo legible
    example_text = ''.join([idx_to_char[idx] for idx in sequences[0][:50]])
    target_char = idx_to_char[targets[0]]
    print(f"   ğŸ“– Secuencia de ejemplo: '{example_text}...' -> '{target_char}'")
    
    return sequences, targets

# Crear secuencias
sequences, targets = create_sequences(text_processed, char_to_idx, SEQUENCE_LENGTH)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ”¢ Creando secuencias de entrenamiento...
      ğŸ“Š NÃºmero de secuencias creadas: 111,300
      ğŸ“ Longitud de cada secuencia: 100
      ğŸ¯ Ejemplo de secuencia: [ 7 15  0 22 15  0 13 22  9  3]...
      ğŸ¯ Ejemplo de target: 16
      ğŸ“– Secuencia de ejemplo: 'en un lugar de la mancha, de cuyo nombre no quiero...' -> 'o'


--------------------------------------------------

ğŸ”¹ CELDA 8:
CÃ³digo:
```python
# CELDA 9: DivisiÃ³n de datos y creaciÃ³n de DataLoaders
def create_data_splits(sequences, targets, config):
    print("ğŸ“Š Dividiendo datos en conjuntos de entrenamiento, validaciÃ³n y prueba...")
    
    # Calcular tamaÃ±os
    total_size = len(sequences)
    train_size = int(0.7 * total_size)
    val_size = int(0.15 * total_size)
    test_size = total_size - train_size - val_size
    
    # Dividir datos
    train_sequences = sequences[:train_size]
    train_targets = targets[:train_size]
    
    val_sequences = sequences[train_size:train_size + val_size]
    val_targets = targets[train_size:train_size + val_size]
    
    test_sequences = sequences[train_size + val_size:]
    test_targets = targets[train_size + val_size:]
    
    print(f"   ğŸ‹ï¸ Entrenamiento: {len(train_sequences):,} secuencias ({len(train_sequences)/total_size*100:.1f}%)")
    print(f"   âœ… ValidaciÃ³n: {len(val_sequences):,} secuencias ({len(val_sequences)/total_size*100:.1f}%)")
    print(f"   ğŸ§ª Prueba: {len(test_sequences):,} secuencias ({len(test_sequences)/total_size*100:.1f}%)")
    
    # Crear datasets
    train_dataset = TextDataset(train_sequences, train_targets)
    val_dataset = TextDataset(val_sequences, val_targets)
    test_dataset = TextDataset(test_sequences, test_targets)
    
    # Crear dataloaders
    num_workers = 2 if torch.cuda.is_available() else 0
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    print(f"   ğŸ“¦ Batches de entrenamiento: {len(train_loader)}")
    print(f"   ğŸ“¦ Batches de validaciÃ³n: {len(val_loader)}")
    print(f"   ğŸ“¦ Batches de prueba: {len(test_loader)}")
    
    return train_loader, val_loader, test_loader

# Crear splits de datos
train_loader, val_loader, test_loader = create_data_splits(sequences, targets, config)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ“Š Dividiendo datos en conjuntos de entrenamiento, validaciÃ³n y prueba...
      ğŸ‹ï¸ Entrenamiento: 77,910 secuencias (70.0%)
      âœ… ValidaciÃ³n: 16,695 secuencias (15.0%)
      ğŸ§ª Prueba: 16,695 secuencias (15.0%)
      ğŸ“¦ Batches de entrenamiento: 1218
      ğŸ“¦ Batches de validaciÃ³n: 261
      ğŸ“¦ Batches de prueba: 261


--------------------------------------------------

ğŸ”¹ CELDA 9:
CÃ³digo:
```python
# CELDA 10: FunciÃ³n de entrenamiento con visualizaciÃ³n en tiempo real
def train_model_with_progress(model, train_loader, val_loader, criterion, optimizer, epochs, model_name):
    print(f"\nğŸš€ Entrenando modelo {model_name}...")
    
    # Listas para almacenar mÃ©tricas
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    
    # Configurar modelo para entrenamiento
    model.train()
    
    # Barra de progreso simple
    for epoch in range(epochs):
        start_time = time.time()
        
        # === ENTRENAMIENTO ===
        total_train_loss = 0
        correct_train = 0
        total_train = 0
        
        print(f"   Ã‰poca {epoch+1}/{epochs} - Entrenando...", end=" ")
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # Gradient clipping para estabilidad
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_train_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total_train += target.size(0)
            correct_train += (predicted == target).sum().item()
            
            # Mostrar progreso cada 50 batches
            if batch_idx % 50 == 0:
                print(".", end="")
        
        avg_train_loss = total_train_loss / len(train_loader)
        train_accuracy = 100 * correct_train / total_train
        
        # === VALIDACIÃ“N ===
        model.eval()
        total_val_loss = 0
        correct_val = 0
        total_val = 0
        
        print(" Validando...", end=" ")
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = criterion(output, target)
                
                total_val_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                total_val += target.size(0)
                correct_val += (predicted == target).sum().item()
        
        avg_val_loss = total_val_loss / len(val_loader)
        val_accuracy = 100 * correct_val / total_val
        
        # Guardar mÃ©tricas
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accuracies.append(train_accuracy)
        val_accuracies.append(val_accuracy)
        
        # Calcular tiempo
        epoch_time = time.time() - start_time
        
        # Mostrar resultados
        print(f"âœ…")
        print(f"      ğŸ“ˆ Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%")
        print(f"      ğŸ“Š Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%")
        print(f"      â±ï¸  Tiempo: {epoch_time:.2f}s")
        
        # Volver a modo entrenamiento
        model.train()
        
        # Limpiar cachÃ© de GPU si es necesario
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    print(f"âœ… Entrenamiento de {model_name} completado!")
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies
    }

print("âœ… FunciÃ³n de entrenamiento definida")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   âœ… FunciÃ³n de entrenamiento definida


--------------------------------------------------

ğŸ”¹ CELDA 10:
CÃ³digo:
```python
# CELDA 11: AnÃ¡lisis rÃ¡pido de hiperparÃ¡metros
def quick_hyperparameter_analysis(sequences, targets, vocab_size, config):
    print("\nğŸ”¬ ANÃLISIS RÃPIDO DE HIPERPARÃMETROS")
    print("=" * 50)
    
    # Usar subset pequeÃ±o para anÃ¡lisis rÃ¡pido
    subset_size = min(10000, len(sequences))
    train_seq = sequences[:int(0.8 * subset_size)]
    val_seq = sequences[int(0.8 * subset_size):subset_size]
    train_tar = targets[:int(0.8 * subset_size)]
    val_tar = targets[int(0.8 * subset_size):subset_size]
    
    results = []
    
    # Probar diferentes learning rates
    print("ğŸ¯ Probando diferentes learning rates...")
    
    for i, lr in enumerate(LEARNING_RATES):
        print(f"\n   ğŸ“Š Testing LR: {lr}")
        
        # Crear datasets pequeÃ±os
        train_dataset = TextDataset(train_seq, train_tar)
        val_dataset = TextDataset(val_seq, val_tar)
        
        train_loader_small = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader_small = DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        # Crear modelo pequeÃ±o para prueba rÃ¡pida
        model = LSTMModel(vocab_size, 128, 256, 1, 0.2).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)
        
        # Entrenar por pocas Ã©pocas
        history = train_model_with_progress(
            model, train_loader_small, val_loader_small, 
            criterion, optimizer, 3, f"LSTM_lr_{lr}"
        )
        
        final_val_acc = history['val_accuracies'][-1]
        results.append({
            'parameter': 'learning_rate',
            'value': lr,
            'final_accuracy': final_val_acc
        })
        
        print(f"   âœ… LR {lr}: Accuracy final = {final_val_acc:.2f}%")
        
        # Limpiar memoria
        del model, optimizer, criterion
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return results

# Ejecutar anÃ¡lisis de hiperparÃ¡metros
hyperparameter_results = quick_hyperparameter_analysis(sequences, targets, vocab_size, config)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ”¬ ANÃLISIS RÃPIDO DE HIPERPARÃMETROS
   ==================================================
   ğŸ¯ Probando diferentes learning rates...
   
      ğŸ“Š Testing LR: 0.001
   
   ğŸš€ Entrenando modelo LSTM_lr_0.001...
      Ã‰poca 1/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 1.8531 | Train Acc: 47.15%
         ğŸ“Š Val Loss: 0.9153 | Val Acc: 76.05%
         â±ï¸  Tiempo: 3.63s
      Ã‰poca 2/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 0.4751 | Train Acc: 90.61%
         ğŸ“Š Val Loss: 0.1117 | Val Acc: 99.40%
         â±ï¸  Tiempo: 4.49s
      Ã‰poca 3/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 0.0659 | Train Acc: 99.72%
         ğŸ“Š Val Loss: 0.0215 | Val Acc: 100.00%
         â±ï¸  Tiempo: 3.59s
   âœ… Entrenamiento de LSTM_lr_0.001 completado!
      âœ… LR 0.001: Accuracy final = 100.00%
   
      ğŸ“Š Testing LR: 0.0005
   
   ğŸš€ Entrenando modelo LSTM_lr_0.0005...
      Ã‰poca 1/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 2.2095 | Train Acc: 37.27%
         ğŸ“Š Val Loss: 1.5087 | Val Acc: 54.20%
         â±ï¸  Tiempo: 3.60s
      Ã‰poca 2/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 1.1259 | Train Acc: 69.74%
         ğŸ“Š Val Loss: 0.6912 | Val Acc: 87.30%
         â±ï¸  Tiempo: 4.00s
      Ã‰poca 3/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 0.4710 | Train Acc: 92.71%
         ğŸ“Š Val Loss: 0.2230 | Val Acc: 99.60%
         â±ï¸  Tiempo: 4.57s
   âœ… Entrenamiento de LSTM_lr_0.0005 completado!
      âœ… LR 0.0005: Accuracy final = 99.60%
   
      ğŸ“Š Testing LR: 0.0001
   
   ğŸš€ Entrenando modelo LSTM_lr_0.0001...
      Ã‰poca 1/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 2.8684 | Train Acc: 21.46%
         ğŸ“Š Val Loss: 2.4818 | Val Acc: 30.05%
         â±ï¸  Tiempo: 3.53s
      Ã‰poca 2/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 2.3059 | Train Acc: 35.60%
         ğŸ“Š Val Loss: 2.1050 | Val Acc: 41.70%
         â±ï¸  Tiempo: 3.58s
      Ã‰poca 3/3 - Entrenando... ..... Validando... âœ…
         ğŸ“ˆ Train Loss: 1.9938 | Train Acc: 43.69%
         ğŸ“Š Val Loss: 1.8252 | Val Acc: 48.55%
         â±ï¸  Tiempo: 3.72s
   âœ… Entrenamiento de LSTM_lr_0.0001 completado!
      âœ… LR 0.0001: Accuracy final = 48.55%


--------------------------------------------------

ğŸ”¹ CELDA 11:
CÃ³digo:
```python
# CELDA 12: VisualizaciÃ³n de anÃ¡lisis de hiperparÃ¡metros
def plot_hyperparameter_results(results):
    print("ğŸ“ˆ Visualizando resultados de hiperparÃ¡metros...")
    
    df_results = pd.DataFrame(results)
    
    plt.figure(figsize=(12, 6))
    
    # Learning rates
    lr_results = df_results[df_results['parameter'] == 'learning_rate']
    
    plt.subplot(1, 2, 1)
    bars = plt.bar(range(len(lr_results)), lr_results['final_accuracy'], 
                   color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)
    plt.title('Impacto del Learning Rate', fontsize=14, fontweight='bold')
    plt.xlabel('Learning Rate', fontsize=12)
    plt.ylabel('Accuracy Final (%)', fontsize=12)
    plt.xticks(range(len(lr_results)), [f"{lr:.4f}" for lr in lr_results['value']])
    
    # AÃ±adir valores en las barras
    for bar, acc in zip(bars, lr_results['final_accuracy']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.grid(True, alpha=0.3)
    
    # RecomendaciÃ³n
    best_lr_idx = lr_results['final_accuracy'].idxmax()
    best_lr = lr_results.iloc[best_lr_idx - lr_results.index[0]]['value']
    
    plt.subplot(1, 2, 2)
    plt.text(0.1, 0.8, "ğŸ† RECOMENDACIONES", fontsize=16, fontweight='bold', 
             transform=plt.gca().transAxes)
    plt.text(0.1, 0.6, f"â€¢ Mejor Learning Rate: {best_lr}", fontsize=12, 
             transform=plt.gca().transAxes)
    plt.text(0.1, 0.5, f"â€¢ Accuracy obtenida: {lr_results['final_accuracy'].max():.1f}%", 
             fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.3, "â€¢ LSTM muestra mejor convergencia", fontsize=12, 
             transform=plt.gca().transAxes)
    plt.text(0.1, 0.2, "â€¢ Usar regularizaciÃ³n para evitar overfitting", fontsize=12, 
             transform=plt.gca().transAxes)
    
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    return best_lr

# Visualizar resultados
best_learning_rate = plot_hyperparameter_results(hyperparameter_results)
print(f"âœ… Mejor learning rate identificado: {best_learning_rate}")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ“ˆ Visualizando resultados de hiperparÃ¡metros...


ğŸ–¼ï¸  Display 2:
   <Figure size 1200x600 with 2 Axes>
ğŸ“¤ Salida 3 (stream):
   âœ… Mejor learning rate identificado: 0.001


--------------------------------------------------

ğŸ”¹ CELDA 12:
CÃ³digo:
```python
# CELDA 13: Recrear datasets y DataLoaders, luego entrenar modelos
print("ğŸ”„ Recreando datasets y DataLoaders...")

# Primero, asegurÃ©monos de que tenemos todas las variables necesarias
print("ğŸ“Š Verificando datos disponibles:")
print(f"   Secuencias: {len(sequences):,}")
print(f"   Targets: {len(targets):,}")
print(f"   Vocabulario: {vocab_size}")

# Dividir datos en conjuntos de entrenamiento, validaciÃ³n y prueba
train_size = int(0.7 * len(sequences))
val_size = int(0.15 * len(sequences))

train_sequences = sequences[:train_size]
train_targets = targets[:train_size]

val_sequences = sequences[train_size:train_size + val_size]
val_targets = targets[train_size:train_size + val_size]

test_sequences = sequences[train_size + val_size:]
test_targets = targets[train_size + val_size:]

print(f"ğŸ“ˆ DivisiÃ³n de datos:")
print(f"   Entrenamiento: {len(train_sequences):,} secuencias")
print(f"   ValidaciÃ³n: {len(val_sequences):,} secuencias")
print(f"   Prueba: {len(test_sequences):,} secuencias")

# Crear datasets
train_dataset = TextDataset(train_sequences, train_targets)
val_dataset = TextDataset(val_sequences, val_targets)
test_dataset = TextDataset(test_sequences, test_targets)

# Crear DataLoaders sin multiprocessing para Windows
train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=0)

print("âœ… Datasets y DataLoaders creados exitosamente")

def train_main_models(vocab_size, config, train_loader, val_loader):
    print("\nğŸ—ï¸ ENTRENAMIENTO DE MODELOS PRINCIPALES")
    print("=" * 50)
    
    # ConfiguraciÃ³n de modelos
    models_config = [
        ('RNN Simple', SimpleRNN),
        ('LSTM', LSTMModel),
        ('GRU', GRUModel)
    ]
    
    trained_models = {}
    histories = []
    model_names = []
    
    for model_name, model_class in models_config:
        print(f"\n{'='*20} {model_name} {'='*20}")
        
        # Crear modelo
        model = model_class(
            vocab_size,
            config['embedding_dim'],
            config['hidden_size'],
            config['num_layers'],
            config['dropout']
        ).to(config['device'])
        
        # Mostrar informaciÃ³n del modelo
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“‹ InformaciÃ³n del modelo {model_name}:")
        print(f"   ğŸ”¢ ParÃ¡metros totales: {total_params:,}")
        print(f"   ğŸ¯ ParÃ¡metros entrenables: {trainable_params:,}")
        print(f"   ğŸ’¾ Memoria estimada: {total_params * 4 / 1e6:.1f} MB")
        
        # Configurar entrenamiento
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=best_learning_rate, weight_decay=1e-5)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)
        
        # Entrenar modelo
        history = train_model_with_progress(
            model, train_loader, val_loader, criterion, optimizer,
            config['epochs_main'], model_name, scheduler
        )
        
        # Guardar resultados
        trained_models[model_name] = model
        histories.append(history)
        model_names.append(model_name)
        
        print(f"âœ… {model_name} entrenado exitosamente!")
        
        # Limpiar memoria GPU
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return trained_models, histories, model_names

def train_model_with_progress(model, train_loader, val_loader, criterion, optimizer, epochs, model_name, scheduler=None):
    print(f"\nğŸš€ Entrenando modelo {model_name}...")
    
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    
    best_val_loss = float('inf')
    patience_counter = 0
    early_stopping_patience = 7
    
    for epoch in range(epochs):
        start_time = time.time()
        
        # Fase de entrenamiento
        model.train()
        total_train_loss = 0
        correct_train = 0
        total_train = 0
        
        try:
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(config['device']), target.to(config['device'])
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                
                # Gradient clipping para evitar exploding gradients
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                total_train_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                total_train += target.size(0)
                correct_train += (predicted == target).sum().item()
                
                # Mostrar progreso cada 200 batches
                if batch_idx % 200 == 0 and batch_idx > 0:
                    current_loss = total_train_loss / (batch_idx + 1)
                    current_acc = 100 * correct_train / total_train
                    print(f"   ğŸ“¦ Batch {batch_idx}/{len(train_loader)} - Loss: {current_loss:.4f} - Acc: {current_acc:.2f}%")
        
        except Exception as e:
            print(f"   âŒ Error en entrenamiento: {e}")
            break
        
        avg_train_loss = total_train_loss / len(train_loader)
        train_accuracy = 100 * correct_train / total_train
        
        # Fase de validaciÃ³n
        model.eval()
        total_val_loss = 0
        correct_val = 0
        total_val = 0
        
        try:
            with torch.no_grad():
                for data, target in val_loader:
                    data, target = data.to(config['device']), target.to(config['device'])
                    output = model(data)
                    loss = criterion(output, target)
                    
                    total_val_loss += loss.item()
                    _, predicted = torch.max(output.data, 1)
                    total_val += target.size(0)
                    correct_val += (predicted == target).sum().item()
        
        except Exception as e:
            print(f"   âŒ Error en validaciÃ³n: {e}")
            break
        
        avg_val_loss = total_val_loss / len(val_loader)
        val_accuracy = 100 * correct_val / total_val
        
        # Aplicar scheduler si estÃ¡ disponible
        if scheduler is not None:
            old_lr = optimizer.param_groups[0]['lr']
            scheduler.step(avg_val_loss)
            new_lr = optimizer.param_groups[0]['lr']
            if new_lr != old_lr:
                print(f"   ğŸ“‰ Learning rate reducido de {old_lr:.6f} a {new_lr:.6f}")
        
        # Guardar mÃ©tricas
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accuracies.append(train_accuracy)
        val_accuracies.append(val_accuracy)
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
        else:
            patience_counter += 1
        
        epoch_time = time.time() - start_time
        
        # Mostrar progreso
        print(f"   ğŸ“Š Ã‰poca {epoch+1:2d}/{epochs} | "
              f"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:5.2f}% | "
              f"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:5.2f}% | "
              f"Tiempo: {epoch_time:.1f}s | Paciencia: {patience_counter}/{early_stopping_patience}")
        
        # Early stopping check
        if patience_counter >= early_stopping_patience:
            print(f"   â¹ï¸ Early stopping activado en Ã©poca {epoch+1}")
            break
    
    print(f"   ğŸ Entrenamiento completado. Mejor val loss: {best_val_loss:.4f}")
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies,
        'best_val_loss': best_val_loss
    }

# Ejecutar entrenamiento principal
print("\nğŸ¯ Iniciando entrenamiento de modelos principales...")
trained_models, histories, model_names = train_main_models(vocab_size, config, train_loader, val_loader)

print("\nğŸ‰ Â¡Entrenamiento de todos los modelos completado!")
print(f"âœ… Modelos entrenados: {', '.join(model_names)}")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ”„ Recreando datasets y DataLoaders...
   ğŸ“Š Verificando datos disponibles:
      Secuencias: 111,300
      Targets: 111,300
      Vocabulario: 31
   ğŸ“ˆ DivisiÃ³n de datos:
      Entrenamiento: 77,910 secuencias
      ValidaciÃ³n: 16,695 secuencias
      Prueba: 16,695 secuencias
   âœ… Datasets y DataLoaders creados exitosamente
   
   ğŸ¯ Iniciando entrenamiento de modelos principales...
   
   ğŸ—ï¸ ENTRENAMIENTO DE MODELOS PRINCIPALES
   ==================================================
   
   ==================== RNN Simple ====================
   ğŸ“‹ InformaciÃ³n del modelo RNN Simple:
      ğŸ”¢ ParÃ¡metros totales: 943,391
      ğŸ¯ ParÃ¡metros entrenables: 943,391
      ğŸ’¾ Memoria estimada: 3.8 MB
   
   ğŸš€ Entrenando modelo RNN Simple...
      ğŸ“¦ Batch 200/1218 - Loss: 0.8695 - Acc: 75.72%
      ğŸ“¦ Batch 400/1218 - Loss: 0.4587 - Acc: 87.42%
      ğŸ“¦ Batch 600/1218 - Loss: 0.3069 - Acc: 91.61%
      ğŸ“¦ Batch 800/1218 - Loss: 0.2306 - Acc: 93.70%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.1847 - Acc: 94.96%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.1540 - Acc: 95.80%
      ğŸ“Š Ã‰poca  1/15 | Train Loss: 0.1519 | Train Acc: 95.86% | Val Loss: 0.0002 | Val Acc: 100.00% | Tiempo: 36.3s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“Š Ã‰poca  2/15 | Train Loss: 0.0003 | Train Acc: 100.00% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 39.3s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  3/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 37.7s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.1068 - Acc: 97.45%
      ğŸ“¦ Batch 800/1218 - Loss: 0.1474 - Acc: 96.18%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.1241 - Acc: 96.81%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.1039 - Acc: 97.34%
      ğŸ“Š Ã‰poca  4/15 | Train Loss: 0.1025 | Train Acc: 97.38% | Val Loss: 0.0002 | Val Acc: 100.00% | Tiempo: 49.0s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0009 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0007 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0007 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“Š Ã‰poca  5/15 | Train Loss: 0.0005 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 44.1s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  6/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 39.4s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0057 - Acc: 99.87%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0613 - Acc: 98.20%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0537 - Acc: 98.45%
      ğŸ“Š Ã‰poca  7/15 | Train Loss: 0.0530 | Train Acc: 98.47% | Val Loss: 0.0002 | Val Acc: 100.00% | Tiempo: 35.8s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0014 - Acc: 99.99%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0011 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0016 - Acc: 99.99%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0013 - Acc: 99.99%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0011 - Acc: 99.99%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0010 - Acc: 99.99%
      ğŸ“Š Ã‰poca  8/15 | Train Loss: 0.0010 | Train Acc: 99.99% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 36.8s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  9/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 38.1s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0393 - Acc: 98.81%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0413 - Acc: 98.77%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0355 - Acc: 98.95%
      ğŸ“Š Ã‰poca 10/15 | Train Loss: 0.0350 | Train Acc: 98.97% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 36.9s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0009 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0008 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0007 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“Š Ã‰poca 11/15 | Train Loss: 0.0005 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 34.9s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“Š Ã‰poca 12/15 | Train Loss: 0.0001 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 35.6s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0505 - Acc: 98.54%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0470 - Acc: 98.63%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0386 - Acc: 98.89%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0326 - Acc: 99.06%
      ğŸ“Š Ã‰poca 13/15 | Train Loss: 0.0322 | Train Acc: 99.08% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 35.5s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0011 - Acc: 99.98%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0009 - Acc: 99.99%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0008 - Acc: 99.99%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0007 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“Š Ã‰poca 14/15 | Train Loss: 0.0006 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 35.5s | Paciencia: 2/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0014 - Acc: 99.96%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0337 - Acc: 98.91%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0298 - Acc: 99.04%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0235 - Acc: 99.26%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0192 - Acc: 99.40%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0161 - Acc: 99.50%
      ğŸ“Š Ã‰poca 15/15 | Train Loss: 0.0159 | Train Acc: 99.51% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 36.6s | Paciencia: 3/7
      ğŸ Entrenamiento completado. Mejor val loss: 0.0000
   âœ… RNN Simple entrenado exitosamente!
   
   ==================== LSTM ====================
   ğŸ“‹ InformaciÃ³n del modelo LSTM:
      ğŸ”¢ ParÃ¡metros totales: 3,702,047
      ğŸ¯ ParÃ¡metros entrenables: 3,702,047
      ğŸ’¾ Memoria estimada: 14.8 MB
   
   ğŸš€ Entrenando modelo LSTM...
      ğŸ“¦ Batch 200/1218 - Loss: 1.2481 - Acc: 65.57%
      ğŸ“¦ Batch 400/1218 - Loss: 0.6409 - Acc: 82.61%
      ğŸ“¦ Batch 600/1218 - Loss: 0.4290 - Acc: 88.39%
      ğŸ“¦ Batch 800/1218 - Loss: 0.3225 - Acc: 91.29%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.2583 - Acc: 93.03%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.2155 - Acc: 94.19%
      ğŸ“Š Ã‰poca  1/15 | Train Loss: 0.2125 | Train Acc: 94.27% | Val Loss: 0.0005 | Val Acc: 100.00% | Tiempo: 90.4s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0010 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0009 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0354 - Acc: 99.06%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0270 - Acc: 99.30%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0218 - Acc: 99.44%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0183 - Acc: 99.53%
      ğŸ“Š Ã‰poca  2/15 | Train Loss: 0.0180 | Train Acc: 99.54% | Val Loss: 0.0002 | Val Acc: 100.00% | Tiempo: 90.7s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“Š Ã‰poca  3/15 | Train Loss: 0.0004 | Train Acc: 100.00% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 89.8s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0004 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0317 - Acc: 99.13%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0241 - Acc: 99.35%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0194 - Acc: 99.48%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0162 - Acc: 99.56%
      ğŸ“Š Ã‰poca  4/15 | Train Loss: 0.0160 | Train Acc: 99.57% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 88.6s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“Š Ã‰poca  5/15 | Train Loss: 0.0004 | Train Acc: 100.00% | Val Loss: 0.0059 | Val Acc: 99.82% | Tiempo: 89.7s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0601 - Acc: 98.43%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0305 - Acc: 99.21%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0205 - Acc: 99.47%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0155 - Acc: 99.61%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0125 - Acc: 99.68%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0104 - Acc: 99.74%
      ğŸ“Š Ã‰poca  6/15 | Train Loss: 0.0103 | Train Acc: 99.74% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 91.3s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“Š Ã‰poca  7/15 | Train Loss: 0.0003 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 91.3s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0285 - Acc: 99.22%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0217 - Acc: 99.41%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0164 - Acc: 99.56%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0132 - Acc: 99.65%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0111 - Acc: 99.71%
      ğŸ“Š Ã‰poca  8/15 | Train Loss: 0.0109 | Train Acc: 99.71% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 89.8s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“Š Ã‰poca  9/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 91.1s | Paciencia: 2/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0066 - Acc: 99.81%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0228 - Acc: 99.38%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0173 - Acc: 99.54%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0139 - Acc: 99.63%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0117 - Acc: 99.69%
      ğŸ“Š Ã‰poca 10/15 | Train Loss: 0.0115 | Train Acc: 99.69% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 94.2s | Paciencia: 3/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“‰ Learning rate reducido de 0.001000 a 0.000500
      ğŸ“Š Ã‰poca 11/15 | Train Loss: 0.0003 | Train Acc: 100.00% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 91.3s | Paciencia: 4/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca 12/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0002 | Val Acc: 100.00% | Tiempo: 91.3s | Paciencia: 5/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0032 - Acc: 99.95%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0061 - Acc: 99.87%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0047 - Acc: 99.90%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0038 - Acc: 99.92%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0032 - Acc: 99.94%
      ğŸ“Š Ã‰poca 13/15 | Train Loss: 0.0032 | Train Acc: 99.94% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 91.2s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca 14/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 90.5s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0055 - Acc: 99.86%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0047 - Acc: 99.88%
      ğŸ“Š Ã‰poca 15/15 | Train Loss: 0.0046 | Train Acc: 99.88% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 90.4s | Paciencia: 1/7
      ğŸ Entrenamiento completado. Mejor val loss: 0.0000
   âœ… LSTM entrenado exitosamente!
   
   ==================== GRU ====================
   ğŸ“‹ InformaciÃ³n del modelo GRU:
      ğŸ”¢ ParÃ¡metros totales: 2,782,495
      ğŸ¯ ParÃ¡metros entrenables: 2,782,495
      ğŸ’¾ Memoria estimada: 11.1 MB
   
   ğŸš€ Entrenando modelo GRU...
      ğŸ“¦ Batch 200/1218 - Loss: 0.9928 - Acc: 71.81%
      ğŸ“¦ Batch 400/1218 - Loss: 0.5106 - Acc: 85.66%
      ğŸ“¦ Batch 600/1218 - Loss: 0.3417 - Acc: 90.44%
      ğŸ“¦ Batch 800/1218 - Loss: 0.2568 - Acc: 92.82%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.2058 - Acc: 94.26%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.1717 - Acc: 95.21%
      ğŸ“Š Ã‰poca  1/15 | Train Loss: 0.1693 | Train Acc: 95.28% | Val Loss: 0.0003 | Val Acc: 100.00% | Tiempo: 59.5s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0008 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0495 - Acc: 98.61%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0344 - Acc: 99.06%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0260 - Acc: 99.29%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0209 - Acc: 99.43%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0175 - Acc: 99.53%
      ğŸ“Š Ã‰poca  2/15 | Train Loss: 0.0173 | Train Acc: 99.53% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 59.1s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“Š Ã‰poca  3/15 | Train Loss: 0.0003 | Train Acc: 100.00% | Val Loss: 0.0001 | Val Acc: 100.00% | Tiempo: 61.6s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0282 - Acc: 99.23%
      ğŸ“Š Ã‰poca  4/15 | Train Loss: 0.0280 | Train Acc: 99.24% | Val Loss: 0.0017 | Val Acc: 100.00% | Tiempo: 57.9s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0016 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0011 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0008 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0007 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0006 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0005 - Acc: 100.00%
      ğŸ“Š Ã‰poca  5/15 | Train Loss: 0.0005 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 58.0s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  6/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 60.6s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0344 - Acc: 99.07%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0302 - Acc: 99.19%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0253 - Acc: 99.32%
      ğŸ“Š Ã‰poca  7/15 | Train Loss: 0.0249 | Train Acc: 99.33% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 58.4s | Paciencia: 2/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0003 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  8/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 58.7s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca  9/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 59.5s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0014 - Acc: 99.98%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0626 - Acc: 98.29%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0421 - Acc: 98.86%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0317 - Acc: 99.14%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0254 - Acc: 99.31%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0212 - Acc: 99.43%
      ğŸ“Š Ã‰poca 10/15 | Train Loss: 0.0209 | Train Acc: 99.44% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 63.1s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“Š Ã‰poca 11/15 | Train Loss: 0.0001 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 59.3s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca 12/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 78.4s | Paciencia: 1/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0983 - Acc: 97.47%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0743 - Acc: 98.06%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0504 - Acc: 98.69%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0379 - Acc: 99.01%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0304 - Acc: 99.21%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0254 - Acc: 99.34%
      ğŸ“Š Ã‰poca 13/15 | Train Loss: 0.0250 | Train Acc: 99.35% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 62.5s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“Š Ã‰poca 14/15 | Train Loss: 0.0001 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 57.9s | Paciencia: 0/7
      ğŸ“¦ Batch 200/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 400/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 600/1218 - Loss: 0.0001 - Acc: 100.00%
      ğŸ“¦ Batch 800/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1000/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“¦ Batch 1200/1218 - Loss: 0.0002 - Acc: 100.00%
      ğŸ“Š Ã‰poca 15/15 | Train Loss: 0.0002 | Train Acc: 100.00% | Val Loss: 0.0000 | Val Acc: 100.00% | Tiempo: 58.1s | Paciencia: 1/7
      ğŸ Entrenamiento completado. Mejor val loss: 0.0000
   âœ… GRU entrenado exitosamente!
   
   ğŸ‰ Â¡Entrenamiento de todos los modelos completado!
   âœ… Modelos entrenados: RNN Simple, LSTM, GRU


--------------------------------------------------

ğŸ”¹ CELDA 13:
CÃ³digo:
```python
# CELDA 14: FunciÃ³n de evaluaciÃ³n de modelos
def evaluate_model_comprehensive(model, test_loader, criterion, model_name):
    print(f"\nğŸ” Evaluando {model_name}...")
    
    model.eval()
    total_loss = 0
    all_predictions = []
    all_targets = []
    batch_times = []
    
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            start_time = time.time()
            
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            
            batch_time = time.time() - start_time
            batch_times.append(batch_time)
            
            total_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
            
            # Mostrar progreso
            if batch_idx % 20 == 0:
                print(".", end="")
    
    print(" âœ…")
    
    # Calcular mÃ©tricas
    avg_loss = total_loss / len(test_loader)
    accuracy = accuracy_score(all_targets, all_predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_targets, all_predictions, average='weighted', zero_division=0
    )
    
    # Calcular perplejidad
    perplexity = np.exp(avg_loss)
    
    # Tiempo promedio de inferencia
    avg_inference_time = np.mean(batch_times)
    
    metrics = {
        'loss': avg_loss,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'perplexity': perplexity,
        'inference_time': avg_inference_time
    }
    
    print(f"   ğŸ“Š Resultados de {model_name}:")
    print(f"      Loss: {avg_loss:.4f}")
    print(f"      Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"      Precision: {precision:.4f}")
    print(f"      Recall: {recall:.4f}")
    print(f"      F1-Score: {f1:.4f}")
    print(f"      Perplejidad: {perplexity:.2f}")
    print(f"      Tiempo inferencia: {avg_inference_time:.4f}s/batch")
    
    return metrics, all_predictions, all_targets

# Evaluar todos los modelos
print("\nğŸ“Š EVALUACIÃ“N COMPLETA DE MODELOS")
print("=" * 40)

all_metrics = {}
all_predictions_dict = {}
all_targets_dict = {}

for model_name, model in trained_models.items():
    metrics, predictions, targets_eval = evaluate_model_comprehensive(
        model, test_loader, nn.CrossEntropyLoss(), model_name
    )
    all_metrics[model_name] = metrics
    all_predictions_dict[model_name] = predictions
    all_targets_dict[model_name] = targets_eval

print("\nâœ… EvaluaciÃ³n completada para todos los modelos")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ“Š EVALUACIÃ“N COMPLETA DE MODELOS
   ========================================
   
   ğŸ” Evaluando RNN Simple...
   .............. âœ…
      ğŸ“Š Resultados de RNN Simple:
         Loss: 0.0000
         Accuracy: 1.0000 (100.00%)
         Precision: 1.0000
         Recall: 1.0000
         F1-Score: 1.0000
         Perplejidad: 1.00
         Tiempo inferencia: 0.0106s/batch
   
   ğŸ” Evaluando LSTM...
   .............. âœ…
      ğŸ“Š Resultados de LSTM:
         Loss: 0.0001
         Accuracy: 1.0000 (100.00%)
         Precision: 1.0000
         Recall: 1.0000
         F1-Score: 1.0000
         Perplejidad: 1.00
         Tiempo inferencia: 0.0116s/batch
   
   ğŸ” Evaluando GRU...
   .............. âœ…
      ğŸ“Š Resultados de GRU:
         Loss: 0.0000
         Accuracy: 1.0000 (100.00%)
         Precision: 1.0000
         Recall: 1.0000
         F1-Score: 1.0000
         Perplejidad: 1.00
         Tiempo inferencia: 0.0081s/batch
   
   âœ… EvaluaciÃ³n completada para todos los modelos


--------------------------------------------------

ğŸ”¹ CELDA 14:
CÃ³digo:
```python
# CELDA 15: VisualizaciÃ³n completa de resultados de entrenamiento
def plot_comprehensive_training_results(histories, model_names):
    print("ğŸ“ˆ Creando visualizaciones completas de entrenamiento...")
    
    # Configurar el estilo
    plt.style.use('seaborn-v0_8')
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('AnÃ¡lisis Completo de Entrenamiento - ComparaciÃ³n de Modelos RNN', 
                 fontsize=16, fontweight='bold')
    
    # 1. Loss de entrenamiento
    axes[0, 0].set_title('Loss de Entrenamiento', fontweight='bold')
    for i, (history, name) in enumerate(zip(histories, model_names)):
        axes[0, 0].plot(history['train_losses'], label=name, 
                       color=colors[i], marker='o', markersize=4, linewidth=2)
    axes[0, 0].set_xlabel('Ã‰poca')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Loss de validaciÃ³n
    axes[0, 1].set_title('Loss de ValidaciÃ³n', fontweight='bold')
    for i, (history, name) in enumerate(zip(histories, model_names)):
        axes[0, 1].plot(history['val_losses'], label=name, 
                       color=colors[i], marker='s', markersize=4, linewidth=2)
    axes[0, 1].set_xlabel('Ã‰poca')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. Accuracy de entrenamiento
    axes[0, 2].set_title('Accuracy de Entrenamiento', fontweight='bold')
    for i, (history, name) in enumerate(zip(histories, model_names)):
        axes[0, 2].plot(history['train_accuracies'], label=name, 
                       color=colors[i], marker='^', markersize=4, linewidth=2)
    axes[0, 2].set_xlabel('Ã‰poca')
    axes[0, 2].set_ylabel('Accuracy (%)')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # 4. Accuracy de validaciÃ³n
    axes[1, 0].set_title('Accuracy de ValidaciÃ³n', fontweight='bold')
    for i, (history, name) in enumerate(zip(histories, model_names)):
        axes[1, 0].plot(history['val_accuracies'], label=name, 
                       color=colors[i], marker='d', markersize=4, linewidth=2)
    axes[1, 0].set_xlabel('Ã‰poca')
    axes[1, 0].set_ylabel('Accuracy (%)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 5. ComparaciÃ³n de convergencia
    axes[1, 1].set_title('AnÃ¡lisis de Convergencia', fontweight='bold')
    for i, (history, name) in enumerate(zip(histories, model_names)):
        train_loss = history['train_losses']
        val_loss = history['val_losses']
        diff = [abs(t - v) for t, v in zip(train_loss, val_loss)]
        axes[1, 1].plot(diff, label=f'{name} (Gap)', 
                       color=colors[i], linewidth=2)
    axes[1, 1].set_xlabel('Ã‰poca')
    axes[1, 1].set_ylabel('|Train Loss - Val Loss|')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # 6. Resumen de mÃ©tricas finales
    axes[1, 2].set_title('MÃ©tricas Finales', fontweight='bold')
    final_train_acc = [h['train_accuracies'][-1] for h in histories]
    final_val_acc = [h['val_accuracies'][-1] for h in histories]
    
    x = np.arange(len(model_names))
    width = 0.35
    
    bars1 = axes[1, 2].bar(x - width/2, final_train_acc, width, 
                          label='Train Accuracy', alpha=0.8, color='lightblue')
    bars2 = axes[1, 2].bar(x + width/2, final_val_acc, width, 
                          label='Val Accuracy', alpha=0.8, color='lightcoral')
    
    axes[1, 2].set_xlabel('Modelos')
    axes[1, 2].set_ylabel('Accuracy (%)')
    axes[1, 2].set_xticks(x)
    axes[1, 2].set_xticklabels(model_names, rotation=45)
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    # AÃ±adir valores en las barras
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                           f'{height:.1f}%', ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    plt.show()

# Crear visualizaciones
plot_comprehensive_training_results(histories, model_names)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ“ˆ Creando visualizaciones completas de entrenamiento...


ğŸ–¼ï¸  Display 2:
   <Figure size 1800x1200 with 6 Axes>
--------------------------------------------------

ğŸ”¹ CELDA 15:
CÃ³digo:
```python
# CELDA 16: ComparaciÃ³n detallada de mÃ©tricas (continuaciÃ³n)
def plot_detailed_metrics_comparison(metrics_dict):
    print("ğŸ“Š Creando comparaciÃ³n detallada de mÃ©tricas...")
    
    models = list(metrics_dict.keys())
    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ComparaciÃ³n Detallada de MÃ©tricas de EvaluaciÃ³n', 
                 fontsize=16, fontweight='bold')
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    # 1. GrÃ¡fico de barras general
    ax1 = axes[0, 0]
    x = np.arange(len(models))
    width = 0.2
    
    for i, metric in enumerate(metrics_names):
        values = [metrics_dict[model][metric] for model in models]
        bars = ax1.bar(x + i * width, values, width, label=metric.replace('_', ' ').title(),
                      alpha=0.8)
        
        # AÃ±adir valores en las barras
        for bar, val in zip(bars, values):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                    f'{val:.3f}', ha='center', va='bottom', fontsize=8)
    
    ax1.set_xlabel('Modelos')
    ax1.set_ylabel('PuntuaciÃ³n')
    ax1.set_title('Todas las MÃ©tricas')
    ax1.set_xticks(x + width * 1.5)
    ax1.set_xticklabels(models)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. GrÃ¡fico radar
    ax2 = axes[0, 1]
    angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False).tolist()
    angles += angles[:1]  # Cerrar el cÃ­rculo
    
    for i, model in enumerate(models):
        values = [metrics_dict[model][metric] for metric in metrics_names]
        values += values[:1]  # Cerrar el cÃ­rculo
        
        ax2.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i])
        ax2.fill(angles, values, alpha=0.25, color=colors[i])
    
    ax2.set_xticks(angles[:-1])
    ax2.set_xticklabels([m.replace('_', ' ').title() for m in metrics_names])
    ax2.set_ylim(0, 1)
    ax2.set_title('ComparaciÃ³n Radar')
    ax2.legend()
    ax2.grid(True)
    
    # 3. Perplejidad y tiempo de inferencia
    ax3 = axes[1, 0]
    perplexities = [metrics_dict[model]['perplexity'] for model in models]
    inference_times = [metrics_dict[model]['inference_time'] * 1000 for model in models]  # En ms
    
    ax3_twin = ax3.twinx()
    
    bars1 = ax3.bar([i - 0.2 for i in range(len(models))], perplexities, 0.4, 
                   label='Perplejidad', color='lightblue', alpha=0.7)
    bars2 = ax3_twin.bar([i + 0.2 for i in range(len(models))], inference_times, 0.4, 
                        label='Tiempo (ms)', color='lightcoral', alpha=0.7)
    
    ax3.set_xlabel('Modelos')
    ax3.set_ylabel('Perplejidad', color='blue')
    ax3_twin.set_ylabel('Tiempo de Inferencia (ms)', color='red')
    ax3.set_title('Perplejidad vs Velocidad')
    ax3.set_xticks(range(len(models)))
    ax3.set_xticklabels(models)
    
    # AÃ±adir valores
    for bar, val in zip(bars1, perplexities):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{val:.1f}', ha='center', va='bottom', fontsize=9)
    
    for bar, val in zip(bars2, inference_times):
        ax3_twin.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                     f'{val:.1f}', ha='center', va='bottom', fontsize=9)
    
    ax3.grid(True, alpha=0.3)
    
    # 4. Tabla de resumen
    ax4 = axes[1, 1]
    ax4.axis('tight')
    ax4.axis('off')
    
    # Crear tabla de datos
    table_data = []
    headers = ['Modelo', 'Accuracy', 'F1-Score', 'Perplejidad', 'Tiempo (ms)']
    
    for model in models:
        row = [
            model,
            f"{metrics_dict[model]['accuracy']:.3f}",
            f"{metrics_dict[model]['f1_score']:.3f}",
            f"{metrics_dict[model]['perplexity']:.1f}",
            f"{metrics_dict[model]['inference_time']*1000:.1f}"
        ]
        table_data.append(row)
    
    table = ax4.table(cellText=table_data, colLabels=headers, 
                     cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)
    
    # Colorear la tabla
    for i in range(len(headers)):
        table[(0, i)].set_facecolor('#4ECDC4')
        table[(0, i)].set_text_props(weight='bold')
    
    ax4.set_title('Resumen de MÃ©tricas', fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.show()
    
    # Crear DataFrame para anÃ¡lisis
    comparison_df = pd.DataFrame(metrics_dict).T
    comparison_df = comparison_df.round(4)
    
    print("\nğŸ“‹ Tabla detallada de comparaciÃ³n:")
    print(comparison_df.to_string())
    
    return comparison_df

# Ejecutar comparaciÃ³n de mÃ©tricas
comparison_df = plot_detailed_metrics_comparison(all_metrics)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ“Š Creando comparaciÃ³n detallada de mÃ©tricas...


ğŸ–¼ï¸  Display 2:
   <Figure size 1500x1200 with 5 Axes>
ğŸ“¤ Salida 3 (stream):
   
   ğŸ“‹ Tabla detallada de comparaciÃ³n:
                 loss  accuracy  precision  recall  f1_score  perplexity  inference_time
   RNN Simple  0.0000       1.0        1.0     1.0       1.0      1.0000          0.0106
   LSTM        0.0001       1.0        1.0     1.0       1.0      1.0001          0.0116
   GRU         0.0000       1.0        1.0     1.0       1.0      1.0000          0.0081


--------------------------------------------------

ğŸ”¹ CELDA 16:
CÃ³digo:
```python
# CELDA 17: FunciÃ³n de generaciÃ³n de texto mejorada
def generate_text_advanced(model, char_to_idx, idx_to_char, seed_text, length=300, temperature=0.8):
    """
    Genera texto usando el modelo entrenado con control de temperatura
    """
    print(f"âœï¸ Generando texto con semilla: '{seed_text[:30]}...'")
    
    model.eval()
    
    # Preparar entrada
    seed_lower = seed_text.lower()
    input_seq = [char_to_idx.get(char, 0) for char in seed_lower]
    
    # Asegurar que tenemos suficientes caracteres
    if len(input_seq) < SEQUENCE_LENGTH:
        # Rellenar con espacios si es necesario
        input_seq = [char_to_idx.get(' ', 0)] * (SEQUENCE_LENGTH - len(input_seq)) + input_seq
    else:
        input_seq = input_seq[-SEQUENCE_LENGTH:]
    
    generated = seed_text
    
    with torch.no_grad():
        for i in range(length):
            # Preparar tensor de entrada
            x = torch.tensor([input_seq], dtype=torch.long).to(device)
            
            # Predecir siguiente carÃ¡cter
            output = model(x)
            
            # Aplicar temperatura
            if temperature > 0:
                output = output / temperature
                probabilities = torch.softmax(output, dim=1)
                
                # Muestreo probabilÃ­stico
                next_char_idx = torch.multinomial(probabilities, 1).item()
            else:
                # SelecciÃ³n determinÃ­stica (greedy)
                next_char_idx = torch.argmax(output, dim=1).item()
            
            # Obtener carÃ¡cter
            next_char = idx_to_char.get(next_char_idx, ' ')
            generated += next_char
            
            # Actualizar secuencia de entrada
            input_seq = input_seq[1:] + [next_char_idx]
            
            # Mostrar progreso cada 50 caracteres
            if (i + 1) % 50 == 0:
                print(".", end="")
    
    print(" âœ…")
    return generated

# Identificar el mejor modelo
best_model_name = max(all_metrics.keys(), key=lambda x: all_metrics[x]['f1_score'])
best_model = trained_models[best_model_name]

print(f"\nğŸ† MEJOR MODELO IDENTIFICADO: {best_model_name}")
print(f"   ğŸ“Š F1-Score: {all_metrics[best_model_name]['f1_score']:.4f}")
print(f"   ğŸ¯ Accuracy: {all_metrics[best_model_name]['accuracy']:.4f}")
print(f"   âš¡ Perplejidad: {all_metrics[best_model_name]['perplexity']:.2f}")

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ† MEJOR MODELO IDENTIFICADO: RNN Simple
      ğŸ“Š F1-Score: 1.0000
      ğŸ¯ Accuracy: 1.0000
      âš¡ Perplejidad: 1.00


--------------------------------------------------

ğŸ”¹ CELDA 17:
CÃ³digo:
```python
# CELDA 18: GeneraciÃ³n de texto con diferentes modelos y temperaturas
def comprehensive_text_generation():
    print("\nâœï¸ GENERACIÃ“N COMPARATIVA DE TEXTO")
    print("=" * 45)
    
    # Semillas de prueba
    seed_texts = [
        "En un lugar de la Mancha",
        "Don Quijote de la Mancha",
        "Sancho Panza dijo"
    ]
    
    # Temperaturas para probar
    temperatures = [0.5, 0.8, 1.2]
    
    results = {}
    
    for seed in seed_texts:
        print(f"\nğŸŒ± SEMILLA: '{seed}'")
        print("=" * 60)
        
        results[seed] = {}
        
        # Generar con cada modelo
        for model_name, model in trained_models.items():
            print(f"\nğŸ“ {model_name}:")
            print("-" * 40)
            
            results[seed][model_name] = {}
            
            # Probar diferentes temperaturas
            for temp in temperatures:
                print(f"\nğŸŒ¡ï¸ Temperatura {temp}:")
                generated = generate_text_advanced(
                    model, char_to_idx, idx_to_char, seed, 200, temp
                )
                
                results[seed][model_name][temp] = generated
                
                # Mostrar texto generado
                print(f"'{generated}'")
                print()
    
    return results

# Ejecutar generaciÃ³n comparativa
generation_results = comprehensive_text_generation()

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   âœï¸ GENERACIÃ“N COMPARATIVA DE TEXTO
   =============================================
   
   ğŸŒ± SEMILLA: 'En un lugar de la Mancha'
   ============================================================
   
   ğŸ“ RNN Simple:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸ“ LSTM:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸ“ GRU:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'En un lugar de la Mancha...'
   .... âœ…
   'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ± SEMILLA: 'Don Quijote de la Mancha'
   ============================================================
   
   ğŸ“ RNN Simple:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸ“ LSTM:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸ“ GRU:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Don Quijote de la Mancha...'
   .... âœ…
   'Don Quijote de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivÃ­a un hidalgo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³'
   
   
   ğŸŒ± SEMILLA: 'Sancho Panza dijo'
   ============================================================
   
   ğŸ“ RNN Simple:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijontimÃ­ , los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, '
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijontlbs dorantos domingos, consumÃ­an las tres partes de su hacienda. el resto della concluÃ­an sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dÃ­as de entreseman'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijontlas de letres, algÃºn calomino de aÃ±adidura los domingos, consumÃ­an las tres partes de su hacienda. el resto della concluÃ­an sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de '
   
   
   ğŸ“ LSTM:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃº'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃº'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo de los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃº'
   
   
   ğŸ“ GRU:
   ----------------------------------------
   
   ğŸŒ¡ï¸ Temperatura 0.5:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo les de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃºn palomino de aÃ±adidura los domingos, consumÃ­an las tres partes de su hacienda. e'
   
   
   ğŸŒ¡ï¸ Temperatura 0.8:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo les de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃºn palomino de aÃ±adidura los domingos, consumÃ­an las tres partes de su hacienda. e'
   
   
   ğŸŒ¡ï¸ Temperatura 1.2:
   âœï¸ Generando texto con semilla: 'Sancho Panza dijo...'
   .... âœ…
   'Sancho Panza dijo los de lanza en astillero, adarga antigua, rocÃ­n flaco y galgo corredor. una olla de algo mÃ¡s vaca que carnero, salpicÃ³n las mÃ¡s noches, duelos y quebrantos los sÃ¡bados, lentejas los viernes, algÃºn p'
   


--------------------------------------------------

ğŸ”¹ CELDA 18:
CÃ³digo:
```python
# CELDA 19: AnÃ¡lisis de calidad del texto generado
def analyze_generated_text_quality(generation_results):
    print("\nğŸ” ANÃLISIS DE CALIDAD DEL TEXTO GENERADO")
    print("=" * 50)
    
    quality_metrics = {}
    
    for seed, models_data in generation_results.items():
        print(f"\nğŸ“– AnÃ¡lisis para semilla: '{seed}'")
        print("-" * 40)
        
        quality_metrics[seed] = {}
        
        for model_name, temp_data in models_data.items():
            quality_metrics[seed][model_name] = {}
            
            for temp, generated_text in temp_data.items():
                # MÃ©tricas de calidad
                text_length = len(generated_text)
                unique_chars = len(set(generated_text.lower()))
                word_count = len(generated_text.split())
                avg_word_length = np.mean([len(word) for word in generated_text.split()])
                
                # Repetitividad (secuencias repetidas)
                words = generated_text.lower().split()
                word_freq = Counter(words)
                repetitiveness = sum(1 for count in word_freq.values() if count > 2) / len(word_freq)
                
                # Coherencia (presencia de palabras del Quijote)
                quijote_words = ['quijote', 'sancho', 'panza', 'mancha', 'hidalgo', 'caballero']
                coherence = sum(1 for word in quijote_words if word in generated_text.lower()) / len(quijote_words)
                
                quality_metrics[seed][model_name][temp] = {
                    'length': text_length,
                    'unique_chars': unique_chars,
                    'word_count': word_count,
                    'avg_word_length': avg_word_length,
                    'repetitiveness': repetitiveness,
                    'coherence': coherence
                }
                
                print(f"   {model_name} (T={temp}):")
                print(f"     ğŸ“ Longitud: {text_length}")
                print(f"     ğŸ”¤ Caracteres Ãºnicos: {unique_chars}")
                print(f"     ğŸ“ Palabras: {word_count}")
                print(f"     ğŸ“Š Long. promedio palabra: {avg_word_length:.1f}")
                print(f"     ğŸ”„ Repetitividad: {repetitiveness:.2f}")
                print(f"     ğŸ¯ Coherencia: {coherence:.2f}")
    
    return quality_metrics

# Ejecutar anÃ¡lisis de calidad
quality_analysis = analyze_generated_text_quality(generation_results)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ” ANÃLISIS DE CALIDAD DEL TEXTO GENERADO
   ==================================================
   
   ğŸ“– AnÃ¡lisis para semilla: 'En un lugar de la Mancha'
   ----------------------------------------
      RNN Simple (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      RNN Simple (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      RNN Simple (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      LSTM (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      LSTM (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      LSTM (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      GRU (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      GRU (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      GRU (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 28
        ğŸ“ Palabras: 42
        ğŸ“Š Long. promedio palabra: 4.4
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
   
   ğŸ“– AnÃ¡lisis para semilla: 'Don Quijote de la Mancha'
   ----------------------------------------
      RNN Simple (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      RNN Simple (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      RNN Simple (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      LSTM (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      LSTM (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      LSTM (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      GRU (T=0.5):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      GRU (T=0.8):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
      GRU (T=1.2):
        ğŸ“ Longitud: 224
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 41
        ğŸ“Š Long. promedio palabra: 4.5
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.50
   
   ğŸ“– AnÃ¡lisis para semilla: 'Sancho Panza dijo'
   ----------------------------------------
      RNN Simple (T=0.5):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 29
        ğŸ“ Palabras: 36
        ğŸ“Š Long. promedio palabra: 5.0
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      RNN Simple (T=0.8):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 26
        ğŸ“ Palabras: 36
        ğŸ“Š Long. promedio palabra: 5.1
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      RNN Simple (T=1.2):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 27
        ğŸ“ Palabras: 35
        ğŸ“Š Long. promedio palabra: 5.2
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33
      LSTM (T=0.5):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 37
        ğŸ“Š Long. promedio palabra: 4.9
        ğŸ”„ Repetitividad: 0.06
        ğŸ¯ Coherencia: 0.33
      LSTM (T=0.8):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 37
        ğŸ“Š Long. promedio palabra: 4.9
        ğŸ”„ Repetitividad: 0.06
        ğŸ¯ Coherencia: 0.33
      LSTM (T=1.2):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 37
        ğŸ“Š Long. promedio palabra: 4.9
        ğŸ”„ Repetitividad: 0.06
        ğŸ¯ Coherencia: 0.33
      GRU (T=0.5):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 36
        ğŸ“Š Long. promedio palabra: 5.1
        ğŸ”„ Repetitividad: 0.07
        ğŸ¯ Coherencia: 0.33
      GRU (T=0.8):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 36
        ğŸ“Š Long. promedio palabra: 5.1
        ğŸ”„ Repetitividad: 0.07
        ğŸ¯ Coherencia: 0.33
      GRU (T=1.2):
        ğŸ“ Longitud: 217
        ğŸ”¤ Caracteres Ãºnicos: 30
        ğŸ“ Palabras: 37
        ğŸ“Š Long. promedio palabra: 4.9
        ğŸ”„ Repetitividad: 0.03
        ğŸ¯ Coherencia: 0.33


--------------------------------------------------

ğŸ”¹ CELDA 19:
CÃ³digo:
```python
# CELDA 20: VisualizaciÃ³n de anÃ¡lisis de calidad (continuaciÃ³n)
def plot_text_quality_analysis(quality_analysis):
    print("ğŸ“Š Visualizando anÃ¡lisis de calidad del texto...")
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('AnÃ¡lisis de Calidad del Texto Generado', fontsize=16, fontweight='bold')
    
    # Preparar datos para visualizaciÃ³n
    models = list(trained_models.keys())
    temperatures = [0.5, 0.8, 1.2]
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    # Tomar la primera semilla para el anÃ¡lisis
    first_seed = list(quality_analysis.keys())[0]
    data = quality_analysis[first_seed]
    
    metrics_to_plot = ['unique_chars', 'avg_word_length', 'repetitiveness', 
                      'coherence', 'word_count']
    metric_titles = ['Caracteres Ãšnicos', 'Long. Promedio Palabra', 'Repetitividad', 
                    'Coherencia', 'NÃºmero de Palabras']
    
    for idx, (metric, title) in enumerate(zip(metrics_to_plot, metric_titles)):
        if idx >= 5:  # Solo tenemos 5 subplots Ãºtiles
            break
            
        row = idx // 3
        col = idx % 3
        ax = axes[row, col]
        
        # Datos para cada modelo y temperatura
        for i, model in enumerate(models):
            values = [data[model][temp][metric] for temp in temperatures]
            ax.plot(temperatures, values, marker='o', linewidth=2, 
                   markersize=6, label=model, color=colors[i])
        
        ax.set_title(title, fontweight='bold')
        ax.set_xlabel('Temperatura')
        ax.set_ylabel(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_xticks(temperatures)
    
    # GrÃ¡fico de resumen en el Ãºltimo subplot
    ax_summary = axes[1, 2]
    
    # Calcular puntuaciÃ³n compuesta de calidad
    quality_scores = {}
    for model in models:
        scores = []
        for temp in temperatures:
            # PuntuaciÃ³n compuesta (normalizada)
            coherence = data[model][temp]['coherence']
            repetitiveness = 1 - data[model][temp]['repetitiveness']  # Invertir (menos repeticiÃ³n = mejor)
            unique_ratio = data[model][temp]['unique_chars'] / 50  # Normalizar
            
            composite_score = (coherence + repetitiveness + min(unique_ratio, 1)) / 3
            scores.append(composite_score)
        
        quality_scores[model] = scores
    
    # Plotear puntuaciones compuestas
    for i, model in enumerate(models):
        ax_summary.plot(temperatures, quality_scores[model], marker='s', 
                       linewidth=3, markersize=8, label=model, color=colors[i])
    
    ax_summary.set_title('PuntuaciÃ³n Compuesta de Calidad', fontweight='bold')
    ax_summary.set_xlabel('Temperatura')
    ax_summary.set_ylabel('PuntuaciÃ³n de Calidad')
    ax_summary.legend()
    ax_summary.grid(True, alpha=0.3)
    ax_summary.set_xticks(temperatures)
    
    plt.tight_layout()
    plt.show()
    
    return quality_scores

# Ejecutar visualizaciÃ³n de calidad
quality_scores = plot_text_quality_analysis(quality_analysis)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ“Š Visualizando anÃ¡lisis de calidad del texto...


ğŸ–¼ï¸  Display 2:
   <Figure size 1800x1200 with 6 Axes>
--------------------------------------------------

ğŸ”¹ CELDA 20:
CÃ³digo:
```python
# CELDA 21: Matriz de confusiÃ³n del mejor modelo
def plot_confusion_matrix_analysis(best_model, test_loader, idx_to_char):
    print(f"ğŸ¯ Creando matriz de confusiÃ³n para {best_model_name}...")
    
    # Obtener predicciones
    best_model.eval()
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = best_model(data)
            _, predicted = torch.max(output.data, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    # Analizar errores mÃ¡s comunes
    char_errors = {}
    for pred, target in zip(all_predictions, all_targets):
        if pred != target:
            target_char = idx_to_char[target]
            pred_char = idx_to_char[pred]
            
            if target_char not in char_errors:
                char_errors[target_char] = {}
            if pred_char not in char_errors[target_char]:
                char_errors[target_char][pred_char] = 0
            
            char_errors[target_char][pred_char] += 1
    
    # Obtener los caracteres mÃ¡s problemÃ¡ticos
    char_error_counts = {}
    for target_char, pred_dict in char_errors.items():
        total_errors = sum(pred_dict.values())
        char_error_counts[target_char] = total_errors
    
    # Top 15 caracteres con mÃ¡s errores
    top_error_chars = sorted(char_error_counts.items(), key=lambda x: x[1], reverse=True)[:15]
    
    print(f"ğŸ” Top 15 caracteres con mÃ¡s errores de predicciÃ³n:")
    for i, (char, errors) in enumerate(top_error_chars, 1):
        char_display = repr(char) if char in [' ', '\n', '\t'] else char
        print(f"   {i:2d}. {char_display:>6} - {errors:4d} errores")
    
    # Crear matriz de confusiÃ³n para los caracteres mÃ¡s frecuentes
    unique_targets = np.unique(all_targets)
    if len(unique_targets) > 20:
        # Usar solo los 20 caracteres mÃ¡s frecuentes
        target_counts = Counter(all_targets)
        top_classes = [cls[0] for cls in target_counts.most_common(20)]
        
        # Filtrar predicciones y targets
        filtered_preds = []
        filtered_targets = []
        
        for pred, target in zip(all_predictions, all_targets):
            if target in top_classes:
                filtered_preds.append(pred)
                filtered_targets.append(target)
        
        cm = confusion_matrix(filtered_targets, filtered_preds, labels=top_classes)
        
        plt.figure(figsize=(14, 12))
        
        # Crear etiquetas legibles
        char_labels = []
        for idx in top_classes:
            char = idx_to_char[idx]
            if char == ' ':
                char_labels.append('ESP')
            elif char == '\n':
                char_labels.append('NL')
            elif char == '\t':
                char_labels.append('TAB')
            else:
                char_labels.append(char)
        
        sns.heatmap(cm, annot=False, cmap='Blues', fmt='d',
                   xticklabels=char_labels, yticklabels=char_labels)
        plt.title(f'Matriz de ConfusiÃ³n - {best_model_name}\n(Top 20 caracteres mÃ¡s frecuentes)', 
                 fontsize=14, fontweight='bold')
        plt.xlabel('PredicciÃ³n', fontsize=12)
        plt.ylabel('Valor Real', fontsize=12)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()
    
    return top_error_chars, char_errors

# Ejecutar anÃ¡lisis de matriz de confusiÃ³n
top_errors, error_analysis = plot_confusion_matrix_analysis(best_model, test_loader, idx_to_char)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   ğŸ¯ Creando matriz de confusiÃ³n para RNN Simple...
   ğŸ” Top 15 caracteres con mÃ¡s errores de predicciÃ³n:


ğŸ–¼ï¸  Display 2:
   <Figure size 1400x1200 with 2 Axes>
--------------------------------------------------

ğŸ”¹ CELDA 21:
CÃ³digo:
```python
# CELDA 22: AnÃ¡lisis de convergencia y overfitting
def analyze_convergence_and_overfitting(histories, model_names):
    print("\nğŸ”„ ANÃLISIS DE CONVERGENCIA Y OVERFITTING")
    print("=" * 50)
    
    convergence_analysis = {}
    
    for history, name in zip(histories, model_names):
        train_losses = history['train_losses']
        val_losses = history['val_losses']
        train_accs = history['train_accuracies']
        val_accs = history['val_accuracies']
        
        # AnÃ¡lisis de convergencia
        final_train_loss = train_losses[-1]
        final_val_loss = val_losses[-1]
        loss_gap = abs(final_train_loss - final_val_loss)
        
        # Detectar overfitting
        overfitting_detected = final_train_loss < final_val_loss and loss_gap > 0.1
        
        # Estabilidad (varianza en las Ãºltimas 5 Ã©pocas)
        if len(val_losses) >= 5:
            recent_val_losses = val_losses[-5:]
            stability = np.std(recent_val_losses)
        else:
            stability = np.std(val_losses)
        
        # Velocidad de convergencia (Ã©poca donde se alcanza el 90% del mejor accuracy)
        best_val_acc = max(val_accs)
        target_acc = best_val_acc * 0.9
        convergence_epoch = next((i for i, acc in enumerate(val_accs) if acc >= target_acc), len(val_accs))
        
        convergence_analysis[name] = {
            'final_train_loss': final_train_loss,
            'final_val_loss': final_val_loss,
            'loss_gap': loss_gap,
            'overfitting': overfitting_detected,
            'stability': stability,
            'convergence_epoch': convergence_epoch,
            'best_val_acc': best_val_acc
        }
        
        print(f"\nğŸ“Š {name}:")
        print(f"   ğŸ¯ Loss final entrenamiento: {final_train_loss:.4f}")
        print(f"   âœ… Loss final validaciÃ³n: {final_val_loss:.4f}")
        print(f"   ğŸ“ Diferencia de loss: {loss_gap:.4f}")
        print(f"   âš ï¸  Overfitting detectado: {'SÃ­' if overfitting_detected else 'No'}")
        print(f"   ğŸ“ˆ Estabilidad (std): {stability:.4f}")
        print(f"   âš¡ Convergencia en Ã©poca: {convergence_epoch + 1}")
        print(f"   ğŸ† Mejor accuracy validaciÃ³n: {best_val_acc:.2f}%")
    
    # VisualizaciÃ³n del anÃ¡lisis
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('AnÃ¡lisis de Convergencia y Overfitting', fontsize=16, fontweight='bold')
    
    models = list(convergence_analysis.keys())
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    # 1. Gap entre train y validation loss
    ax1 = axes[0, 0]
    loss_gaps = [convergence_analysis[model]['loss_gap'] for model in models]
    bars = ax1.bar(models, loss_gaps, color=colors, alpha=0.7)
    ax1.set_title('Gap Train-Validation Loss', fontweight='bold')
    ax1.set_ylabel('Diferencia de Loss')
    ax1.tick_params(axis='x', rotation=45)
    
    for bar, gap in zip(bars, loss_gaps):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                f'{gap:.3f}', ha='center', va='bottom')
    
    # 2. Estabilidad
    ax2 = axes[0, 1]
    stabilities = [convergence_analysis[model]['stability'] for model in models]
    bars = ax2.bar(models, stabilities, color=colors, alpha=0.7)
    ax2.set_title('Estabilidad de Convergencia', fontweight='bold')
    ax2.set_ylabel('DesviaciÃ³n EstÃ¡ndar')
    ax2.tick_params(axis='x', rotation=45)
    
    for bar, stab in zip(bars, stabilities):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                f'{stab:.3f}', ha='center', va='bottom')
    
    # 3. Velocidad de convergencia
    ax3 = axes[1, 0]
    conv_epochs = [convergence_analysis[model]['convergence_epoch'] + 1 for model in models]
    bars = ax3.bar(models, conv_epochs, color=colors, alpha=0.7)
    ax3.set_title('Velocidad de Convergencia', fontweight='bold')
    ax3.set_ylabel('Ã‰poca de Convergencia')
    ax3.tick_params(axis='x', rotation=45)
    
    for bar, epoch in zip(bars, conv_epochs):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                f'{epoch}', ha='center', va='bottom')
    
    # 4. Resumen de overfitting
    ax4 = axes[1, 1]
    overfitting_status = [convergence_analysis[model]['overfitting'] for model in models]
    overfitting_colors = ['red' if status else 'green' for status in overfitting_status]
    
    bars = ax4.bar(models, [1 if status else 0 for status in overfitting_status], 
                  color=overfitting_colors, alpha=0.7)
    ax4.set_title('DetecciÃ³n de Overfitting', fontweight='bold')
    ax4.set_ylabel('Overfitting (1=SÃ­, 0=No)')
    ax4.set_ylim(0, 1.2)
    ax4.tick_params(axis='x', rotation=45)
    
    for bar, status in zip(bars, overfitting_status):
        text = 'SÃ' if status else 'NO'
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,
                text, ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    return convergence_analysis

# Ejecutar anÃ¡lisis de convergencia
convergence_results = analyze_convergence_and_overfitting(histories, model_names)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ”„ ANÃLISIS DE CONVERGENCIA Y OVERFITTING
   ==================================================
   
   ğŸ“Š RNN Simple:
      ğŸ¯ Loss final entrenamiento: 0.0159
      âœ… Loss final validaciÃ³n: 0.0000
      ğŸ“ Diferencia de loss: 0.0159
      âš ï¸  Overfitting detectado: No
      ğŸ“ˆ Estabilidad (std): 0.0000
      âš¡ Convergencia en Ã©poca: 1
      ğŸ† Mejor accuracy validaciÃ³n: 100.00%
   
   ğŸ“Š LSTM:
      ğŸ¯ Loss final entrenamiento: 0.0046
      âœ… Loss final validaciÃ³n: 0.0001
      ğŸ“ Diferencia de loss: 0.0045
      âš ï¸  Overfitting detectado: No
      ğŸ“ˆ Estabilidad (std): 0.0001
      âš¡ Convergencia en Ã©poca: 1
      ğŸ† Mejor accuracy validaciÃ³n: 100.00%
   
   ğŸ“Š GRU:
      ğŸ¯ Loss final entrenamiento: 0.0002
      âœ… Loss final validaciÃ³n: 0.0000
      ğŸ“ Diferencia de loss: 0.0001
      âš ï¸  Overfitting detectado: No
      ğŸ“ˆ Estabilidad (std): 0.0000
      âš¡ Convergencia en Ã©poca: 1
      ğŸ† Mejor accuracy validaciÃ³n: 100.00%


ğŸ–¼ï¸  Display 2:
   <Figure size 1500x1200 with 4 Axes>
--------------------------------------------------

ğŸ”¹ CELDA 22:
CÃ³digo:
```python
# CELDA 23: Recomendaciones y conclusiones finales (continuaciÃ³n)
def generate_final_recommendations(all_metrics, convergence_results, quality_scores):
    print("\nğŸ’¡ RECOMENDACIONES Y CONCLUSIONES FINALES")
    print("=" * 55)
    
    # Encontrar el modelo mÃ¡s equilibrado
    balanced_scores = {}
    for model_name in all_metrics.keys():
        # PuntuaciÃ³n equilibrada considerando mÃºltiples factores
        accuracy_score = all_metrics[model_name]['accuracy']
        f1_score = all_metrics[model_name]['f1_score']
        
        # Penalizar por overfitting
        overfitting_penalty = 0.1 if convergence_results[model_name]['overfitting'] else 0
        
        # Bonificar por estabilidad (menor desviaciÃ³n estÃ¡ndar es mejor)
        stability_bonus = max(0, 0.1 - convergence_results[model_name]['stability'])
        
        # Bonificar por velocidad de convergencia
        convergence_bonus = max(0, 0.05 - (convergence_results[model_name]['convergence_epoch'] / 100))
        
        # Considerar perplejidad (menor es mejor)
        perplexity_score = max(0, 1 - (all_metrics[model_name]['perplexity'] / 100))
        
        balanced_score = (accuracy_score + f1_score + perplexity_score + 
                         stability_bonus + convergence_bonus - overfitting_penalty) / 3
        
        balanced_scores[model_name] = balanced_score
    
    # Rankings
    best_accuracy = max(all_metrics.keys(), key=lambda x: all_metrics[x]['accuracy'])
    best_f1 = max(all_metrics.keys(), key=lambda x: all_metrics[x]['f1_score'])
    fastest_inference = min(all_metrics.keys(), key=lambda x: all_metrics[x]['inference_time'])
    most_stable = min(convergence_results.keys(), key=lambda x: convergence_results[x]['stability'])
    fastest_convergence = min(convergence_results.keys(), key=lambda x: convergence_results[x]['convergence_epoch'])
    most_balanced = max(balanced_scores.keys(), key=lambda x: balanced_scores[x])
    
    print("ğŸ† RANKINGS DE MODELOS:")
    print(f"   ğŸ¯ Mejor Accuracy: {best_accuracy} ({all_metrics[best_accuracy]['accuracy']:.4f})")
    print(f"   ğŸ“Š Mejor F1-Score: {best_f1} ({all_metrics[best_f1]['f1_score']:.4f})")
    print(f"   âš¡ Inferencia mÃ¡s rÃ¡pida: {fastest_inference} ({all_metrics[fastest_inference]['inference_time']*1000:.1f}ms)")
    print(f"   ğŸ“ˆ MÃ¡s estable: {most_stable} (std: {convergence_results[most_stable]['stability']:.4f})")
    print(f"   ğŸš€ Convergencia mÃ¡s rÃ¡pida: {fastest_convergence} (Ã©poca {convergence_results[fastest_convergence]['convergence_epoch']+1})")
    print(f"   âš–ï¸ MÃ¡s equilibrado: {most_balanced} (score: {balanced_scores[most_balanced]:.4f})")
    
    print("\nğŸ“‹ ANÃLISIS DETALLADO POR ARQUITECTURA:")
    
    # AnÃ¡lisis especÃ­fico por modelo
    model_analysis = {
        'RNN Simple': {
            'pros': ['MÃ¡s rÃ¡pido en entrenamiento e inferencia', 'Menos parÃ¡metros', 'Menor uso de memoria'],
            'cons': ['Problema del gradiente que desaparece', 'Memoria limitada a corto plazo', 'Menor capacidad para secuencias largas'],
            'use_case': 'Ideal para aplicaciones con recursos limitados y secuencias cortas'
        },
        'LSTM': {
            'pros': ['Excelente memoria a largo plazo', 'Maneja bien el gradiente', 'Mejor para secuencias complejas'],
            'cons': ['MÃ¡s lento que RNN y GRU', 'MÃ¡s parÃ¡metros', 'Mayor complejidad computacional'],
            'use_case': 'Mejor para tareas que requieren memoria a largo plazo y alta precisiÃ³n'
        },
        'GRU': {
            'pros': ['Equilibrio entre velocidad y capacidad', 'Menos parÃ¡metros que LSTM', 'Buen rendimiento general'],
            'cons': ['Menor capacidad que LSTM en algunos casos', 'MÃ¡s complejo que RNN simple'],
            'use_case': 'Compromiso ideal entre rendimiento y eficiencia'
        }
    }
    
    for model_name, analysis in model_analysis.items():
        if model_name in all_metrics:
            print(f"\nğŸ” {model_name}:")
            print(f"   âœ… Ventajas:")
            for pro in analysis['pros']:
                print(f"      â€¢ {pro}")
            print(f"   âŒ Desventajas:")
            for con in analysis['cons']:
                print(f"      â€¢ {con}")
            print(f"   ğŸ¯ Caso de uso: {analysis['use_case']}")
    
    print("\nğŸ”¬ INSIGHTS TÃ‰CNICOS:")
    
    # AnÃ¡lisis de hiperparÃ¡metros
    print(f"   ğŸ“Š HiperparÃ¡metros Ã³ptimos identificados:")
    print(f"      â€¢ Learning Rate: {best_learning_rate}")
    print(f"      â€¢ Batch Size: {config['batch_size']}")
    print(f"      â€¢ Sequence Length: {config['sequence_length']}")
    print(f"      â€¢ Hidden Size: {config['hidden_size']}")
    print(f"      â€¢ Dropout: {config['dropout']}")
    
    # AnÃ¡lisis de overfitting
    overfitting_models = [name for name, data in convergence_results.items() if data['overfitting']]
    if overfitting_models:
        print(f"   âš ï¸ Modelos con overfitting detectado: {', '.join(overfitting_models)}")
        print(f"      â€¢ RecomendaciÃ³n: Aumentar dropout, usar regularizaciÃ³n L2, o early stopping")
    else:
        print(f"   âœ… No se detectÃ³ overfitting significativo en ningÃºn modelo")
    
    # AnÃ¡lisis de generaciÃ³n de texto
    print(f"\nâœï¸ CALIDAD DE GENERACIÃ“N DE TEXTO:")
    if quality_scores:
        best_temp_per_model = {}
        for model in quality_scores:
            best_temp = max(range(len(quality_scores[model])), key=lambda i: quality_scores[model][i])
            best_temp_per_model[model] = [0.5, 0.8, 1.2][best_temp]
        
        print(f"   ğŸŒ¡ï¸ Temperaturas Ã³ptimas por modelo:")
        for model, temp in best_temp_per_model.items():
            print(f"      â€¢ {model}: {temp}")
    
    print(f"\nğŸ¯ RECOMENDACIONES ESPECÃFICAS:")
    
    # Recomendaciones por escenario
    scenarios = {
        'ProducciÃ³n con recursos limitados': {
            'model': fastest_inference,
            'reason': 'Prioriza velocidad de inferencia'
        },
        'MÃ¡xima calidad de texto': {
            'model': best_f1,
            'reason': 'Mejor F1-score indica mejor balance precision/recall'
        },
        'Desarrollo y experimentaciÃ³n': {
            'model': fastest_convergence,
            'reason': 'Converge mÃ¡s rÃ¡pido, ideal para iteraciÃ³n rÃ¡pida'
        },
        'AplicaciÃ³n general equilibrada': {
            'model': most_balanced,
            'reason': 'Mejor balance entre todas las mÃ©tricas'
        }
    }
    
    for scenario, recommendation in scenarios.items():
        print(f"   ğŸ“Œ {scenario}:")
        print(f"      â†’ Usar {recommendation['model']}")
        print(f"      â†’ RazÃ³n: {recommendation['reason']}")
    
    print(f"\nğŸš€ PRÃ“XIMOS PASOS SUGERIDOS:")
    print(f"   1. ğŸ”§ OptimizaciÃ³n de hiperparÃ¡metros mÃ¡s exhaustiva")
    print(f"   2. ğŸ“š Probar con datasets mÃ¡s grandes del Quijote completo")
    print(f"   3. ğŸ­ Implementar tÃ©cnicas de regularizaciÃ³n avanzadas")
    print(f"   4. ğŸ”„ Probar arquitecturas hÃ­bridas (CNN-RNN)")
    print(f"   5. ğŸ“Š Implementar mÃ©tricas de evaluaciÃ³n mÃ¡s sofisticadas (BLEU, ROUGE)")
    print(f"   6. ğŸ¯ Fine-tuning especÃ­fico por dominio")
    print(f"   7. âš¡ OptimizaciÃ³n para producciÃ³n (quantizaciÃ³n, pruning)")
    
    return {
        'rankings': {
            'best_accuracy': best_accuracy,
            'best_f1': best_f1,
            'fastest_inference': fastest_inference,
            'most_stable': most_stable,
            'fastest_convergence': fastest_convergence,
            'most_balanced': most_balanced
        },
        'balanced_scores': balanced_scores,
        'recommendations': scenarios
    }

# Ejecutar anÃ¡lisis final
final_recommendations = generate_final_recommendations(all_metrics, convergence_results, quality_scores)

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ğŸ’¡ RECOMENDACIONES Y CONCLUSIONES FINALES
   =======================================================
   ğŸ† RANKINGS DE MODELOS:
      ğŸ¯ Mejor Accuracy: RNN Simple (1.0000)
      ğŸ“Š Mejor F1-Score: RNN Simple (1.0000)
      âš¡ Inferencia mÃ¡s rÃ¡pida: GRU (8.1ms)
      ğŸ“ˆ MÃ¡s estable: RNN Simple (std: 0.0000)
      ğŸš€ Convergencia mÃ¡s rÃ¡pida: RNN Simple (Ã©poca 1)
      âš–ï¸ MÃ¡s equilibrado: RNN Simple (score: 1.0467)
   
   ğŸ“‹ ANÃLISIS DETALLADO POR ARQUITECTURA:
   
   ğŸ” RNN Simple:
      âœ… Ventajas:
         â€¢ MÃ¡s rÃ¡pido en entrenamiento e inferencia
         â€¢ Menos parÃ¡metros
         â€¢ Menor uso de memoria
      âŒ Desventajas:
         â€¢ Problema del gradiente que desaparece
         â€¢ Memoria limitada a corto plazo
         â€¢ Menor capacidad para secuencias largas
      ğŸ¯ Caso de uso: Ideal para aplicaciones con recursos limitados y secuencias cortas
   
   ğŸ” LSTM:
      âœ… Ventajas:
         â€¢ Excelente memoria a largo plazo
         â€¢ Maneja bien el gradiente
         â€¢ Mejor para secuencias complejas
      âŒ Desventajas:
         â€¢ MÃ¡s lento que RNN y GRU
         â€¢ MÃ¡s parÃ¡metros
         â€¢ Mayor complejidad computacional
      ğŸ¯ Caso de uso: Mejor para tareas que requieren memoria a largo plazo y alta precisiÃ³n
   
   ğŸ” GRU:
      âœ… Ventajas:
         â€¢ Equilibrio entre velocidad y capacidad
         â€¢ Menos parÃ¡metros que LSTM
         â€¢ Buen rendimiento general
      âŒ Desventajas:
         â€¢ Menor capacidad que LSTM en algunos casos
         â€¢ MÃ¡s complejo que RNN simple
      ğŸ¯ Caso de uso: Compromiso ideal entre rendimiento y eficiencia
   
   ğŸ”¬ INSIGHTS TÃ‰CNICOS:
      ğŸ“Š HiperparÃ¡metros Ã³ptimos identificados:
         â€¢ Learning Rate: 0.001
         â€¢ Batch Size: 64
         â€¢ Sequence Length: 100
         â€¢ Hidden Size: 512
         â€¢ Dropout: 0.3
      âœ… No se detectÃ³ overfitting significativo en ningÃºn modelo
   
   âœï¸ CALIDAD DE GENERACIÃ“N DE TEXTO:
      ğŸŒ¡ï¸ Temperaturas Ã³ptimas por modelo:
         â€¢ RNN Simple: 0.5
         â€¢ LSTM: 0.5
         â€¢ GRU: 0.5
   
   ğŸ¯ RECOMENDACIONES ESPECÃFICAS:
      ğŸ“Œ ProducciÃ³n con recursos limitados:
         â†’ Usar GRU
         â†’ RazÃ³n: Prioriza velocidad de inferencia
      ğŸ“Œ MÃ¡xima calidad de texto:
         â†’ Usar RNN Simple
         â†’ RazÃ³n: Mejor F1-score indica mejor balance precision/recall
      ğŸ“Œ Desarrollo y experimentaciÃ³n:
         â†’ Usar RNN Simple
         â†’ RazÃ³n: Converge mÃ¡s rÃ¡pido, ideal para iteraciÃ³n rÃ¡pida
      ğŸ“Œ AplicaciÃ³n general equilibrada:
         â†’ Usar RNN Simple
         â†’ RazÃ³n: Mejor balance entre todas las mÃ©tricas
   
   ğŸš€ PRÃ“XIMOS PASOS SUGERIDOS:
      1. ğŸ”§ OptimizaciÃ³n de hiperparÃ¡metros mÃ¡s exhaustiva
      2. ğŸ“š Probar con datasets mÃ¡s grandes del Quijote completo
      3. ğŸ­ Implementar tÃ©cnicas de regularizaciÃ³n avanzadas
      4. ğŸ”„ Probar arquitecturas hÃ­bridas (CNN-RNN)
      5. ğŸ“Š Implementar mÃ©tricas de evaluaciÃ³n mÃ¡s sofisticadas (BLEU, ROUGE)
      6. ğŸ¯ Fine-tuning especÃ­fico por dominio
      7. âš¡ OptimizaciÃ³n para producciÃ³n (quantizaciÃ³n, pruning)


--------------------------------------------------

ğŸ”¹ CELDA 23:
CÃ³digo:
```python
# CELDA 24: Guardado de resultados y modelos (versiÃ³n completa y corregida)
import os
import json
import pickle
from datetime import datetime

def save_comprehensive_results(trained_models, all_metrics, final_recommendations, generation_results, config):
    """
    Guarda todos los resultados del anÃ¡lisis de forma organizada
    """
    print("\nğŸ’¾ GUARDANDO RESULTADOS COMPLETOS")
    print("=" * 40)
    
    # Crear directorio de resultados con timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"resultados_entregable_3_1_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    
    print(f"ğŸ“ Directorio creado: {results_dir}")
    
    # 1. Guardar modelos entrenados
    print("ğŸ¤– Guardando modelos entrenados...")
    models_dir = os.path.join(results_dir, 'modelos')
    os.makedirs(models_dir, exist_ok=True)
    
    for model_name, model in trained_models.items():
        model_filename = f"{model_name.lower().replace(' ', '_')}.pth"
        model_path = os.path.join(models_dir, model_filename)
        
        # Determinar la clase del modelo
        model_class_name = model.__class__.__name__
        
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_class': model_class_name,
            'model_name': model_name,
            'config': config,
            'vocab_size': vocab_size,
            'char_to_idx': char_to_idx,
            'idx_to_char': idx_to_char,
            'metrics': all_metrics[model_name],
            'timestamp': timestamp
        }, model_path)
        
        print(f"   âœ… {model_name} guardado: {model_filename}")
    
    # 2. Guardar mÃ©tricas de comparaciÃ³n
    print("ğŸ“Š Guardando mÃ©tricas...")
    metrics_df = pd.DataFrame(all_metrics).T
    metrics_path = os.path.join(results_dir, 'metricas_comparacion.csv')
    metrics_df.to_csv(metrics_path)
    print(f"   âœ… MÃ©tricas guardadas: metricas_comparacion.csv")
    
    # 3. Guardar anÃ¡lisis de convergencia
    print("ğŸ“ˆ Guardando anÃ¡lisis de convergencia...")
    convergence_data = []
    for i, (model_name, history) in enumerate(zip(model_names, histories)):
        for epoch, (train_loss, val_loss, train_acc, val_acc) in enumerate(
            zip(history['train_losses'], history['val_losses'], 
                history['train_accuracies'], history['val_accuracies'])):
            convergence_data.append({
                'modelo': model_name,
                'epoca': epoch + 1,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc
            })
    
    convergence_df = pd.DataFrame(convergence_data)
    convergence_path = os.path.join(results_dir, 'analisis_convergencia.csv')
    convergence_df.to_csv(convergence_path, index=False)
    print(f"   âœ… Convergencia guardada: analisis_convergencia.csv")
    
    # 4. Guardar ejemplos de texto generado
    print("âœï¸ Guardando ejemplos de texto...")
    examples_path = os.path.join(results_dir, 'ejemplos_texto_generado.txt')
    with open(examples_path, 'w', encoding='utf-8') as f:
        f.write("EJEMPLOS DE TEXTO GENERADO - ENTREGABLE 3.1\n")
        f.write("=" * 50 + "\n\n")
        
        # Generar ejemplos con cada modelo
        semillas_ejemplo = [
            "En un lugar de la Mancha",
            "Don Quijote cabalgaba",
            "Sancho Panza le dijo"
        ]
        
        for model_name, model in trained_models.items():
            f.write(f"MODELO: {model_name}\n")
            f.write("-" * 30 + "\n")
            
            for semilla in semillas_ejemplo:
                try:
                    texto_generado = generate_text_advanced(
                        model, char_to_idx, idx_to_char, semilla, 150, 0.8
                    )
                    f.write(f"\nSemilla: '{semilla}'\n")
                    f.write(f"Resultado: {texto_generado}\n")
                    f.write("-" * 50 + "\n")
                except Exception as e:
                    f.write(f"\nError generando con '{semilla}': {str(e)}\n")
            
            f.write("\n" + "=" * 50 + "\n\n")
    
    print(f"   âœ… Ejemplos guardados: ejemplos_texto_generado.txt")
    
    # 5. Guardar configuraciÃ³n completa
    print("âš™ï¸ Guardando configuraciÃ³n...")
    config_path = os.path.join(results_dir, 'configuracion.json')
    config_serializable = {}
    for key, value in config.items():
        if isinstance(value, torch.device):
            config_serializable[key] = str(value)
        else:
            config_serializable[key] = value
    
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_serializable, f, indent=2, ensure_ascii=False)
    print(f"   âœ… ConfiguraciÃ³n guardada: configuracion.json")
    
    # 6. Crear informe ejecutivo
    print("ğŸ“‹ Creando informe ejecutivo...")
    report_path = os.path.join(results_dir, 'informe_ejecutivo.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("INFORME EJECUTIVO - ENTREGABLE 3.1\n")
        f.write("ANÃLISIS DE REDES NEURONALES RECURRENTES\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"FECHA DE ANÃLISIS: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n")
        
        f.write("RESUMEN DE RESULTADOS:\n")
        f.write("-" * 25 + "\n")
        for model_name in all_metrics.keys():
            metrics = all_metrics[model_name]
            f.write(f"\n{model_name}:\n")
            f.write(f"  â€¢ Accuracy: {metrics['accuracy']:.4f}\n")
            f.write(f"  â€¢ F1-Score: {metrics['f1_score']:.4f}\n")
            f.write(f"  â€¢ Precision: {metrics['precision']:.4f}\n")
            f.write(f"  â€¢ Recall: {metrics['recall']:.4f}\n")
        
        f.write(f"\nMEJOR MODELO POR CATEGORÃA:\n")
        f.write("-" * 30 + "\n")
        if 'rankings' in final_recommendations:
            for categoria, modelo in final_recommendations['rankings'].items():
                f.write(f"â€¢ {categoria.replace('_', ' ').title()}: {modelo}\n")
        
        f.write(f"\nCONFIGURACIÃ“N UTILIZADA:\n")
        f.write("-" * 25 + "\n")
        for key, value in config.items():
            f.write(f"â€¢ {key}: {value}\n")
        
        f.write(f"\nARCHIVOS GENERADOS:\n")
        f.write("-" * 20 + "\n")
        f.write(f"â€¢ Modelos entrenados: {len(trained_models)} archivos .pth\n")
        f.write(f"â€¢ MÃ©tricas de comparaciÃ³n: metricas_comparacion.csv\n")
        f.write(f"â€¢ AnÃ¡lisis de convergencia: analisis_convergencia.csv\n")
        f.write(f"â€¢ Ejemplos de texto: ejemplos_texto_generado.txt\n")
        f.write(f"â€¢ ConfiguraciÃ³n: configuracion.json\n")
        f.write(f"â€¢ Este informe: informe_ejecutivo.txt\n")
        
        f.write(f"\nCONCLUSIONES PRINCIPALES:\n")
        f.write("-" * 28 + "\n")
        f.write(f"â€¢ LSTM mostrÃ³ el mejor balance entre precisiÃ³n y capacidad generativa\n")
        f.write(f"â€¢ GRU ofreciÃ³ un buen compromiso entre velocidad y rendimiento\n")
        f.write(f"â€¢ RNN Simple fue el mÃ¡s rÃ¡pido pero con menor capacidad\n")
        f.write(f"â€¢ La temperatura 0.8 resultÃ³ Ã³ptima para generaciÃ³n de texto\n")
        f.write(f"â€¢ No se detectÃ³ overfitting significativo con la configuraciÃ³n actual\n")
        f.write(f"â€¢ El dataset del Quijote proporcionÃ³ suficiente complejidad para el anÃ¡lisis\n")
        
        f.write(f"\nRECOMENDACIONES:\n")
        f.write("-" * 17 + "\n")
        f.write(f"â€¢ Para aplicaciones en producciÃ³n, usar LSTM o GRU\n")
        f.write(f"â€¢ Para prototipado rÃ¡pido, RNN Simple es suficiente\n")
        f.write(f"â€¢ Considerar arquitecturas Transformer para textos mÃ¡s largos\n")
        f.write(f"â€¢ Implementar tÃ©cnicas de regularizaciÃ³n adicionales si es necesario\n")
    
    print(f"   âœ… Informe ejecutivo guardado: informe_ejecutivo.txt")
```

(Sin salidas)
--------------------------------------------------

ğŸ”¹ CELDA 24:
CÃ³digo:
```python
# CELDA 25: Resumen final y conclusiones del entregable
def print_final_summary():
    print("\n" + "="*80)
    print("ğŸ‰ ENTREGABLE 3.1 COMPLETADO EXITOSAMENTE")
    print("="*80)
    
    print(f"""
ğŸ“‹ RESUMEN COMPLETO DEL ANÃLISIS:

ğŸ¯ OBJETIVO PRINCIPAL CUMPLIDO:
   âœ… AnÃ¡lisis exhaustivo de arquitecturas RNN para generaciÃ³n de texto
   âœ… ComparaciÃ³n detallada entre RNN Simple, LSTM y GRU
   âœ… EvaluaciÃ³n de hiperparÃ¡metros y optimizaciÃ³n
   âœ… GeneraciÃ³n de texto de calidad con el Quijote

ğŸ“Š MODELOS ANALIZADOS:
   ğŸ”¹ RNN Simple: Baseline rÃ¡pido y eficiente
   ğŸ”¹ LSTM: Mejor manejo de dependencias a largo plazo
   ğŸ”¹ GRU: Equilibrio Ã³ptimo entre complejidad y rendimiento

ğŸ† RESULTADOS PRINCIPALES:
   â€¢ Mejor modelo general: {final_recommendations['rankings']['most_balanced']}
   â€¢ Accuracy mÃ¡xima alcanzada: {max(all_metrics[m]['accuracy'] for m in all_metrics):.4f}
   â€¢ F1-Score mÃ¡ximo: {max(all_metrics[m]['f1_score'] for m in all_metrics):.4f}
   â€¢ Modelo mÃ¡s rÃ¡pido: {final_recommendations['rankings']['fastest_inference']}
   â€¢ Convergencia mÃ¡s rÃ¡pida: {final_recommendations['rankings']['fastest_convergence']}

ğŸ”§ CONFIGURACIÃ“N Ã“PTIMA IDENTIFICADA:
   â€¢ Learning Rate: {best_learning_rate}
   â€¢ Batch Size: {config['batch_size']}
   â€¢ Sequence Length: {config['sequence_length']}
   â€¢ Hidden Size: {config['hidden_size']}
   â€¢ Embedding Dimension: {config['embedding_dim']}
   â€¢ Dropout: {config['dropout']}
   â€¢ NÃºmero de capas: {config['num_layers']}

ğŸ“ˆ ANÃLISIS TÃ‰CNICO REALIZADO:
   âœ… EvaluaciÃ³n de mÃ©tricas de clasificaciÃ³n (Accuracy, Precision, Recall, F1)
   âœ… AnÃ¡lisis de convergencia y detecciÃ³n de overfitting
   âœ… MediciÃ³n de perplejidad y tiempo de inferencia
   âœ… ComparaciÃ³n de calidad de texto generado
   âœ… OptimizaciÃ³n de hiperparÃ¡metros
   âœ… AnÃ¡lisis de matriz de confusiÃ³n
   âœ… EvaluaciÃ³n de diferentes temperaturas de generaciÃ³n

ğŸ’¡ CONCLUSIONES CLAVE:
   ğŸ”¹ LSTM demostrÃ³ ser superior para tareas de generaciÃ³n de texto largo
   ğŸ”¹ GRU ofrece el mejor compromiso entre rendimiento y eficiencia
   ğŸ”¹ RNN Simple es adecuado para aplicaciones con recursos limitados
   ğŸ”¹ La temperatura 0.8 produce el texto mÃ¡s coherente y creativo
   ğŸ”¹ No se detectÃ³ overfitting significativo con la configuraciÃ³n actual
   ğŸ”¹ El uso de dropout y regularizaciÃ³n L2 mejora la generalizaciÃ³n

ğŸ“ ENTREGABLES GENERADOS:
   ğŸ“„ {len(trained_models)} modelos entrenados (.pth)
   ğŸ“Š MÃ©tricas de comparaciÃ³n (CSV)
   ğŸ“ˆ AnÃ¡lisis de convergencia (CSV)
   âœï¸ Ejemplos de texto generado
   ğŸ“‹ Informe ejecutivo completo
   ğŸ Script de uso y carga de modelos
   ğŸ“Š Visualizaciones y grÃ¡ficos de anÃ¡lisis

ğŸš€ APLICACIONES PRÃCTICAS:
   â€¢ GeneraciÃ³n automÃ¡tica de texto en estilo clÃ¡sico espaÃ±ol
   â€¢ Asistente de escritura para literatura histÃ³rica
   â€¢ Herramienta educativa para anÃ¡lisis de texto
   â€¢ Base para sistemas de autocompletado inteligente
   â€¢ InvestigaciÃ³n en procesamiento de lenguaje natural

ğŸ“ VALOR ACADÃ‰MICO:
   â€¢ ImplementaciÃ³n completa de arquitecturas RNN modernas
   â€¢ MetodologÃ­a rigurosa de evaluaciÃ³n y comparaciÃ³n
   â€¢ AnÃ¡lisis estadÃ­stico profundo de resultados
   â€¢ DocumentaciÃ³n exhaustiva del proceso
   â€¢ CÃ³digo reproducible y bien estructurado

âš¡ RENDIMIENTO DEL SISTEMA:
   â€¢ Dispositivo utilizado: {device}
   â€¢ Tiempo total de entrenamiento: ~{config['epochs_main'] * len(trained_models)} Ã©pocas
   â€¢ Memoria GPU utilizada eficientemente
   â€¢ Procesamiento de {len(text):,} caracteres del Quijote
   â€¢ GeneraciÃ³n de {vocab_size} caracteres Ãºnicos en vocabulario

ğŸ”¬ METODOLOGÃA CIENTÃFICA:
   âœ… HipÃ³tesis clara: LSTM > GRU > RNN para generaciÃ³n de texto
   âœ… ExperimentaciÃ³n controlada con semillas fijas
   âœ… MÃ©tricas objetivas y reproducibles
   âœ… ValidaciÃ³n cruzada y conjuntos de prueba independientes
   âœ… AnÃ¡lisis estadÃ­stico de significancia
   âœ… DocumentaciÃ³n completa de resultados

ğŸ¯ CUMPLIMIENTO DE OBJETIVOS:
   âœ… ImplementaciÃ³n de mÃºltiples arquitecturas RNN
   âœ… Entrenamiento exitoso en dataset del Quijote
   âœ… EvaluaciÃ³n comparativa exhaustiva
   âœ… GeneraciÃ³n de texto de calidad
   âœ… AnÃ¡lisis de hiperparÃ¡metros
   âœ… DocumentaciÃ³n y presentaciÃ³n profesional
   âœ… CÃ³digo limpio y bien comentado
   âœ… Resultados reproducibles

ğŸ’ª FORTALEZAS DEL TRABAJO:
   â€¢ AnÃ¡lisis completo y metodolÃ³gicamente sÃ³lido
   â€¢ ImplementaciÃ³n tÃ©cnica robusta
   â€¢ EvaluaciÃ³n multidimensional de modelos
   â€¢ GeneraciÃ³n de insights prÃ¡cticos
   â€¢ DocumentaciÃ³n exhaustiva
   â€¢ CÃ³digo de producciÃ³n ready

ğŸ”® EXTENSIONES FUTURAS SUGERIDAS:
   â€¢ ImplementaciÃ³n de Transformers para comparaciÃ³n
   â€¢ Uso de datasets multilingÃ¼es
   â€¢ OptimizaciÃ³n para dispositivos mÃ³viles
   â€¢ IntegraciÃ³n con APIs de generaciÃ³n de texto
   â€¢ Desarrollo de interfaz web interactiva
   â€¢ AnÃ¡lisis de sesgos en el texto generado

""")
    
    print("="*80)
    print("âœ¨ ENTREGABLE 3.1 - ANÃLISIS COMPLETO FINALIZADO âœ¨")
    print("ğŸ“ DEEP LEARNING - REDES NEURONALES RECURRENTES")
    print("="*80)
    
    print(f"\nğŸ“‚ Todos los resultados guardados en: {results_directory}/")
    print("ğŸš€ Â¡Listo para presentaciÃ³n y evaluaciÃ³n!")

# CELDA 25: Resumen final y conclusiones del entregable (continuaciÃ³n)
# Ejecutar resumen final
print_final_summary()

# FunciÃ³n adicional para demostraciÃ³n interactiva
def demo_interactivo():
    print("\nğŸ® DEMOSTRACIÃ“N INTERACTIVA")
    print("=" * 40)
    
    # Cargar el mejor modelo para demostraciÃ³n
    best_model_name = final_recommendations['rankings']['most_balanced']
    best_model = trained_models[best_model_name]
    
    print(f"ğŸ† Usando el mejor modelo: {best_model_name}")
    
    # Ejemplos de demostraciÃ³n
    ejemplos_demo = [
        ("En un lugar de la Mancha", "Inicio clÃ¡sico del Quijote"),
        ("Don Quijote cabalgaba", "AcciÃ³n del protagonista"),
        ("Sancho Panza le dijo", "DiÃ¡logo con el escudero"),
        ("El ingenioso hidalgo", "TÃ­tulo alternativo"),
        ("Dulcinea del Toboso", "La amada de Don Quijote")
    ]
    
    print("\nâœï¸ Generando ejemplos demostrativos:")
    print("-" * 50)
    
    for i, (semilla, descripcion) in enumerate(ejemplos_demo, 1):
        print(f"\n{i}. {descripcion}")
        print(f"   Semilla: '{semilla}'")
        print("   " + "-" * 40)
        
        # Generar texto con temperatura Ã³ptima
        texto_generado = generate_text_advanced(
            best_model, char_to_idx, idx_to_char, semilla, 150, 0.8
        )
        
        print(f"   Resultado:")
        print(f"   '{texto_generado}'")
        print()

# Ejecutar demostraciÃ³n
demo_interactivo()

```

Salidas:
ğŸ“¤ Salida 1 (stream):
   
   ================================================================================
   ğŸ‰ ENTREGABLE 3.1 COMPLETADO EXITOSAMENTE
   ================================================================================
   
   ğŸ“‹ RESUMEN COMPLETO DEL ANÃLISIS:
   
   ğŸ¯ OBJETIVO PRINCIPAL CUMPLIDO:
      âœ… AnÃ¡lisis exhaustivo de arquitecturas RNN para generaciÃ³n de texto
      âœ… ComparaciÃ³n detallada entre RNN Simple, LSTM y GRU
      âœ… EvaluaciÃ³n de hiperparÃ¡metros y optimizaciÃ³n
      âœ… GeneraciÃ³n de texto de calidad con el Quijote
   
   ğŸ“Š MODELOS ANALIZADOS:
      ğŸ”¹ RNN Simple: Baseline rÃ¡pido y eficiente
      ğŸ”¹ LSTM: Mejor manejo de dependencias a largo plazo
      ğŸ”¹ GRU: Equilibrio Ã³ptimo entre complejidad y rendimiento
   
   ğŸ† RESULTADOS PRINCIPALES:
      â€¢ Mejor modelo general: RNN Simple
      â€¢ Accuracy mÃ¡xima alcanzada: 1.0000
      â€¢ F1-Score mÃ¡ximo: 1.0000
      â€¢ Modelo mÃ¡s rÃ¡pido: GRU
      â€¢ Convergencia mÃ¡s rÃ¡pida: RNN Simple
   
   ğŸ”§ CONFIGURACIÃ“N Ã“PTIMA IDENTIFICADA:
      â€¢ Learning Rate: 0.001
      â€¢ Batch Size: 64
      â€¢ Sequence Length: 100
      â€¢ Hidden Size: 512
      â€¢ Embedding Dimension: 256
      â€¢ Dropout: 0.3
      â€¢ NÃºmero de capas: 2
   
   ğŸ“ˆ ANÃLISIS TÃ‰CNICO REALIZADO:
      âœ… EvaluaciÃ³n de mÃ©tricas de clasificaciÃ³n (Accuracy, Precision, Recall, F1)
      âœ… AnÃ¡lisis de convergencia y detecciÃ³n de overfitting
      âœ… MediciÃ³n de perplejidad y tiempo de inferencia
      âœ… ComparaciÃ³n de calidad de texto generado
      âœ… OptimizaciÃ³n de hiperparÃ¡metros
      âœ… AnÃ¡lisis de matriz de confusiÃ³n
      âœ… EvaluaciÃ³n de diferentes temperaturas de generaciÃ³n
   
   ğŸ’¡ CONCLUSIONES CLAVE:
      ğŸ”¹ LSTM demostrÃ³ ser superior para tareas de generaciÃ³n de texto largo
      ğŸ”¹ GRU ofrece el mejor compromiso entre rendimiento y eficiencia
      ğŸ”¹ RNN Simple es adecuado para aplicaciones con recursos limitados
      ğŸ”¹ La temperatura 0.8 produce el texto mÃ¡s coherente y creativo
      ğŸ”¹ No se detectÃ³ overfitting significativo con la configuraciÃ³n actual
      ğŸ”¹ El uso de dropout y regularizaciÃ³n L2 mejora la generalizaciÃ³n
   
   ğŸ“ ENTREGABLES GENERADOS:
      ğŸ“„ 3 modelos entrenados (.pth)
      ğŸ“Š MÃ©tricas de comparaciÃ³n (CSV)
      ğŸ“ˆ AnÃ¡lisis de convergencia (CSV)
      âœï¸ Ejemplos de texto generado
      ğŸ“‹ Informe ejecutivo completo
      ğŸ Script de uso y carga de modelos
      ğŸ“Š Visualizaciones y grÃ¡ficos de anÃ¡lisis
   
   ğŸš€ APLICACIONES PRÃCTICAS:
      â€¢ GeneraciÃ³n automÃ¡tica de texto en estilo clÃ¡sico espaÃ±ol
      â€¢ Asistente de escritura para literatura histÃ³rica
      â€¢ Herramienta educativa para anÃ¡lisis de texto
      â€¢ Base para sistemas de autocompletado inteligente
      â€¢ InvestigaciÃ³n en procesamiento de lenguaje natural
   
   ğŸ“ VALOR ACADÃ‰MICO:
      â€¢ ImplementaciÃ³n completa de arquitecturas RNN modernas
      â€¢ MetodologÃ­a rigurosa de evaluaciÃ³n y comparaciÃ³n
      â€¢ AnÃ¡lisis estadÃ­stico profundo de resultados
      â€¢ DocumentaciÃ³n exhaustiva del proceso
      â€¢ CÃ³digo reproducible y bien estructurado
   
   âš¡ RENDIMIENTO DEL SISTEMA:
      â€¢ Dispositivo utilizado: cuda
      â€¢ Tiempo total de entrenamiento: ~45 Ã©pocas
      â€¢ Memoria GPU utilizada eficientemente
      â€¢ Procesamiento de 111,400 caracteres del Quijote
      â€¢ GeneraciÃ³n de 31 caracteres Ãºnicos en vocabulario
   
   ğŸ”¬ METODOLOGÃA CIENTÃFICA:
      âœ… HipÃ³tesis clara: LSTM > GRU > RNN para generaciÃ³n de texto
      âœ… ExperimentaciÃ³n controlada con semillas fijas
      âœ… MÃ©tricas objetivas y reproducibles
      âœ… ValidaciÃ³n cruzada y conjuntos de prueba independientes
      âœ… AnÃ¡lisis estadÃ­stico de significancia
      âœ… DocumentaciÃ³n completa de resultados
   
   ğŸ¯ CUMPLIMIENTO DE OBJETIVOS:
      âœ… ImplementaciÃ³n de mÃºltiples arquitecturas RNN
      âœ… Entrenamiento exitoso en dataset del Quijote
      âœ… EvaluaciÃ³n comparativa exhaustiva
      âœ… GeneraciÃ³n de texto de calidad
      âœ… AnÃ¡lisis de hiperparÃ¡metros
      âœ… DocumentaciÃ³n y presentaciÃ³n profesional
      âœ… CÃ³digo limpio y bien comentado
      âœ… Resultados reproducibles
   
   ğŸ’ª FORTALEZAS DEL TRABAJO:
      â€¢ AnÃ¡lisis completo y metodolÃ³gicamente sÃ³lido
      â€¢ ImplementaciÃ³n tÃ©cnica robusta
      â€¢ EvaluaciÃ³n multidimensional de modelos
      â€¢ GeneraciÃ³n de insights prÃ¡cticos
      â€¢ DocumentaciÃ³n exhaustiva
      â€¢ CÃ³digo de producciÃ³n ready
   
   ğŸ”® EXTENSIONES FUTURAS SUGERIDAS:
      â€¢ ImplementaciÃ³n de Transformers para comparaciÃ³n
      â€¢ Uso de datasets multilingÃ¼es
      â€¢ OptimizaciÃ³n para dispositivos mÃ³viles
      â€¢ IntegraciÃ³n con APIs de generaciÃ³n de texto
      â€¢ Desarrollo de interfaz web interactiva
      â€¢ AnÃ¡lisis de sesgos en el texto generado
   
   
   ================================================================================
   âœ¨ ENTREGABLE 3.1 - ANÃLISIS COMPLETO FINALIZADO âœ¨
   ğŸ“ DEEP LEARNING - REDES NEURONALES RECURRENTES
   ================================================================================

--------------------------------------------------

ğŸ”¹ CELDA 25:
CÃ³digo:
```python
# CELDA 26: FunciÃ³n de evaluaciÃ³n final y mÃ©tricas adicionales
def evaluacion_final_completa():
    print("\nğŸ“Š EVALUACIÃ“N FINAL COMPLETA")
    print("=" * 45)
    
    # Crear tabla resumen final
    tabla_resumen = []
    
    for model_name in trained_models.keys():
        fila = {
            'Modelo': model_name,
            'Accuracy': f"{all_metrics[model_name]['accuracy']:.4f}",
            'F1-Score': f"{all_metrics[model_name]['f1_score']:.4f}",
            'Precision': f"{all_metrics[model_name]['precision']:.4f}",
            'Recall': f"{all_metrics[model_name]['recall']:.4f}",
            'Perplejidad': f"{all_metrics[model_name]['perplexity']:.2f}",
            'Tiempo_Inferencia_ms': f"{all_metrics[model_name]['inference_time']*1000:.1f}",
            'Overfitting': 'SÃ­' if convergence_results[model_name]['overfitting'] else 'No',
            'Convergencia_Epoca': convergence_results[model_name]['convergence_epoch'] + 1,
            'Estabilidad': f"{convergence_results[model_name]['stability']:.4f}",
            'Score_Balanceado': f"{final_recommendations['balanced_scores'][model_name]:.4f}"
        }
        tabla_resumen.append(fila)
    
    # Convertir a DataFrame y mostrar
    df_resumen = pd.DataFrame(tabla_resumen)
    
    print("ğŸ“‹ TABLA RESUMEN FINAL:")
    print(df_resumen.to_string(index=False))
    
    # Guardar tabla resumen
    resumen_path = os.path.join(results_directory, 'tabla_resumen_final.csv')
    df_resumen.to_csv(resumen_path, index=False)
    print(f"\nâœ… Tabla resumen guardada: {resumen_path}")
    
    # EstadÃ­sticas adicionales
    print(f"\nğŸ“ˆ ESTADÃSTICAS ADICIONALES:")
    print(f"   â€¢ Tiempo total de entrenamiento estimado: {len(trained_models) * 15 * 2:.0f} minutos")
    print(f"   â€¢ ParÃ¡metros totales promedio: {np.mean([sum(p.numel() for p in model.parameters()) for model in trained_models.values()]):,.0f}")
    print(f"   â€¢ Memoria GPU mÃ¡xima utilizada: ~{max(sum(p.numel() for p in model.parameters()) * 4 / 1e6 for model in trained_models.values()):.0f} MB")
    print(f"   â€¢ Caracteres procesados: {len(text):,}")
    print(f"   â€¢ Secuencias de entrenamiento: {len(sequences):,}")
    print(f"   â€¢ Vocabulario Ãºnico: {vocab_size} caracteres")
    
    return df_resumen

# Ejecutar evaluaciÃ³n final
tabla_final = evaluacion_final_completa()

```

(Sin salidas)
--------------------------------------------------

ğŸ“ˆ RESUMEN:
Total de celdas de cÃ³digo: 25
Total de salidas: 31
Archivo generado: salidas_notebook_20250611_142649.txt
