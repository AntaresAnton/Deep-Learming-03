
    <!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Informe Final - Comparación de Modelos NLP</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 20px;
                color: #333;
                max-width: 1200px;
                margin: 0 auto;
            }
            h1, h2, h3 {
                color: #2c3e50;
            }
            h1 {
                text-align: center;
                border-bottom: 2px solid #3498db;
                padding-bottom: 10px;
            }
            h2 {
                border-bottom: 1px solid #bdc3c7;
                padding-bottom: 5px;
                margin-top: 30px;
            }
            table {
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
            }
            th, td {
                padding: 12px 15px;
                text-align: left;
                border-bottom: 1px solid #ddd;
            }
            th {
                background-color: #f2f2f2;
                font-weight: bold;
            }
            tr:hover {
                background-color: #f5f5f5;
            }
            .highlight {
                background-color: #e8f4f8;
                font-weight: bold;
            }
            .container {
                display: flex;
                flex-wrap: wrap;
                justify-content: space-between;
            }
            .chart-container {
                width: 48%;
                margin-bottom: 20px;
                box-shadow: 0 0 10px rgba(0,0,0,0.1);
                padding: 15px;
                border-radius: 5px;
            }
            .full-width {
                width: 100%;
            }
            .conclusion {
                background-color: #f9f9f9;
                padding: 15px;
                border-left: 4px solid #3498db;
                margin: 20px 0;
            }
            .footer {
                text-align: center;
                margin-top: 50px;
                padding-top: 20px;
                border-top: 1px solid #ddd;
                color: #7f8c8d;
            }
            .advantage {
                color: #27ae60;
            }
            .disadvantage {
                color: #e74c3c;
            }
        </style>
    </head>
    <body>
        <h1>Informe Final: Comparación de Modelos RNN/LSTM y Transformer para NLP</h1>
        
        <h2>1. Resumen Ejecutivo</h2>
        <p>
            Este informe presenta un análisis comparativo entre diferentes arquitecturas de redes neuronales
            para el procesamiento de lenguaje natural (NLP): RNN simple, LSTM, GRU y Transformer.
            Se evaluaron estos modelos en términos de precisión, métricas específicas de NLP y eficiencia computacional.
        </p>
        
        <h2>2. Configuración Experimental</h2>
        <p>
            <strong>Parámetros de los modelos:</strong>
            <ul>
                <li>Dimensión de entrada/salida: 10000</li>
                <li>Dimensión de embedding: 256</li>
                <li>Dimensión oculta: 512</li>
                <li>Número de capas: 2</li>
                <li>Número de cabezas (Transformer): 8</li>
                <li>Dropout: 0.3</li>
                <li>Tasa de aprendizaje: 0.001</li>
                <li>Épocas de entrenamiento: 10</li>
            </ul>
        </p>
        
        <h2>3. Resultados Comparativos</h2>
        
        <h3>3.1. Tabla de Métricas</h3>
        <table>
            <tr>
                <th>Métrica</th>
    <th>RNN</th><th>LSTM</th><th>GRU</th><th>Transformer</th>
            </tr>
    
            <tr>
                <td>Accuracy</td>
        <td>0.4965</td><td class='highlight'>0.5170</td><td>0.5126</td><td>0.5101</td>
            </tr>
        
            <tr>
                <td>Precision</td>
        <td>0.4759</td><td>0.5312</td><td>0.5333</td><td class='highlight'>0.5905</td>
            </tr>
        
            <tr>
                <td>Recall</td>
        <td>0.4623</td><td class='highlight'>0.4646</td><td>0.4554</td><td>0.4328</td>
            </tr>
        
            <tr>
                <td>F1-Score</td>
        <td>0.4468</td><td class='highlight'>0.4665</td><td>0.4360</td><td>0.4200</td>
            </tr>
        
            <tr>
                <td>BLEU</td>
        <td class='highlight'>0.3359</td><td>0.3134</td><td>0.2969</td><td>0.2727</td>
            </tr>
        
            <tr>
                <td>ROUGE-1</td>
        <td>0.7882</td><td class='highlight'>0.7892</td><td>0.7398</td><td>0.7248</td>
            </tr>
        
            <tr>
                <td>ROUGE-2</td>
        <td class='highlight'>0.4748</td><td>0.4732</td><td>0.4634</td><td>0.4681</td>
            </tr>
        
            <tr>
                <td>ROUGE-L</td>
        <td class='highlight'>0.7721</td><td>0.7609</td><td>0.7155</td><td>0.7029</td>
            </tr>
        
            <tr>
                <td>Tiempo de inferencia relativo</td>
    <td>2.42x</td><td>1.93x</td><td>1.64x</td><td class='highlight'>1.00x</td>
            </tr>
        </table>
        
        <h3>3.2. Visualizaciones</h3>
        
        <div class="container">
            <div class="chart-container">
                <h4>Comparación de Accuracy</h4>
                <img src="comparison_accuracy.png" alt="Comparación de Accuracy" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Comparación de F1-Score</h4>
                <img src="comparison_f1.png" alt="Comparación de F1-Score" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Comparación de BLEU</h4>
                <img src="comparison_bleu.png" alt="Comparación de BLEU" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Comparación de ROUGE-L</h4>
                <img src="comparison_rouge-l.png" alt="Comparación de ROUGE-L" width="100%">
            </div>
            
            <div class="chart-container full-width">
                <h4>Tiempos de Inferencia Relativos</h4>
                <img src="inference_times.png" alt="Tiempos de Inferencia" width="100%">
            </div>
        </div>
        
        <h3>3.3. Análisis de Hiperparámetros</h3>
        
        <div class="container">
            <div class="chart-container">
                <h4>Impacto del Número de Capas (LSTM)</h4>
                <img src="impact_n_layers_f1.png" alt="Impacto del Número de Capas" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Impacto de la Tasa de Aprendizaje (LSTM)</h4>
                <img src="impact_learning_rate_f1.png" alt="Impacto de la Tasa de Aprendizaje" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Impacto del Número de Capas (Transformer)</h4>
                <img src="impact_n_layers_f1.png" alt="Impacto del Número de Capas (Transformer)" width="100%">
            </div>
            
            <div class="chart-container">
                <h4>Impacto del Número de Cabezas (Transformer)</h4>
                <img src="impact_n_heads_f1.png" alt="Impacto del Número de Cabezas" width="100%">
            </div>
        </div>
        
        <h2>4. Análisis Comparativo</h2>
        
        <h3>4.1. Mejor Modelo RNN/LSTM vs Transformer</h3>
    
        <p>
            El mejor modelo de la familia RNN/LSTM fue <strong>LSTM</strong> con un F1-score de 0.4665.
            En comparación, el modelo Transformer obtuvo un F1-score de 0.4200.
        </p>
        
        <div class="container">
            <div class="chart-container full-width">
                <h4>Comparación Final: LSTM vs Transformer</h4>
                <img src="final_comparison_f1.png" alt="Comparación Final" width="100%">
            </div>
        </div>
    
        <h3>4.2. Componentes Clave del Transformer</h3>
        <p>
            El modelo Transformer se distingue por varios componentes clave que contribuyen a su rendimiento:
        </p>
        <ul>
            <li><strong>Mecanismo de Autoatención:</strong> Permite al modelo atender a diferentes partes de la secuencia de entrada simultáneamente, facilitando la captura de dependencias a larga distancia.</li>
            <li><strong>Codificación Posicional:</strong> Proporciona información sobre la posición de cada token en la secuencia, compensando la falta de recurrencia.</li>
            <li><strong>Arquitectura Encoder-Decoder:</strong> Permite procesar la entrada y generar la salida de manera eficiente, con un flujo de información bien estructurado.</li>
            <li><strong>Multi-Head Attention:</strong> Permite al modelo atender a diferentes representaciones del espacio simultáneamente, capturando diferentes tipos de relaciones.</li>
        </ul>
        
        <h2>5. Conclusiones</h2>
        
        <div class="conclusion">
    
            <p>
                <strong>1. Comparación de Arquitecturas:</strong><br>
                El mejor modelo RNN/LSTM (LSTM) superó al Transformer en términos de F1-score,
                lo que sugiere que para este conjunto de datos específico, las arquitecturas recurrentes pueden ser más adecuadas.
            </p>
        
            <p>
                En términos de BLEU score, el modelo LSTM mostró un mejor rendimiento, lo que sugiere
                que puede ser más adecuado para ciertas tareas de generación de texto en este contexto.
            </p>
        
            <p>
                En cuanto a eficiencia computacional, el Transformer fue más rápido en inferencia que el mejor modelo RNN/LSTM,
                lo que destaca otra ventaja de su arquitectura paralela.
            </p>
        
            <p>
                <strong>2. Impacto de Hiperparámetros:</strong><br>
                - Número de capas: Un mayor número de capas puede mejorar el rendimiento hasta cierto punto, pero también aumenta el riesgo de sobreajuste.<br>
                - Tasa de aprendizaje: Una tasa de aprendizaje adecuada es crucial para la convergencia del modelo.<br>
                - Número de cabezas de atención (Transformer): Más cabezas permiten capturar diferentes tipos de relaciones en los datos.
            </p>
            
            <p>
                <strong>3. Ventajas y Desventajas:</strong><br>
                - RNN/LSTM:
                <ul>
                    <li class="advantage">Ventajas: Más simples, menos parámetros, eficientes para secuencias cortas.</li>
                    <li class="disadvantage">Desventajas: Dificultad para capturar dependencias a largo plazo, procesamiento secuencial.</li>
                </ul>
                
                - Transformer:
                <ul>
                    <li class="advantage">Ventajas: Paralelización, mejor captura de dependencias a largo plazo, atención a diferentes partes de la secuencia.</li>
                    <li class="disadvantage">Desventajas: Mayor número de parámetros, requiere más datos para entrenar efectivamente.</li>
                </ul>
            </p>
        </div>
        
        <h2>6. Recomendaciones</h2>
        <p>
            Basado en los resultados de este estudio, se pueden hacer las siguientes recomendaciones:
        </p>
        <ul>
            <li>Para tareas de NLP con secuencias largas y dependencias a distancia, considerar el uso de Transformers.</li>
            <li>Para aplicaciones con recursos limitados o conjuntos de datos pequeños, los modelos LSTM/GRU pueden ser más adecuados.</li>
            <li>La selección del modelo debe considerar no solo la precisión, sino también la eficiencia computacional según los requisitos específicos.</li>
            <li>Es recomendable realizar un ajuste cuidadoso de hiperparámetros, especialmente el número de capas y la tasa de aprendizaje.</li>
            <li>Para aplicaciones en tiempo real, considerar el equilibrio entre precisión y tiempo de inferencia.</li>
        </ul>
        
        <div class="footer">
            <p>Informe generado automáticamente - Análisis de Modelos RNN/LSTM y Transformer para NLP</p>
            <p>Fecha: 22/06/2025</p>
        </div>
    </body>
    </html>
    